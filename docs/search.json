[
  {
    "objectID": "4.4_durations.html",
    "href": "4.4_durations.html",
    "title": "4.4 Results - Durations",
    "section": "",
    "text": "Code\n# Setup code\nimport pandas as pd\nfrom python_scripts import setup\nfrom python_scripts import services\nfrom python_scripts import helper\ndf, dffp = setup.setup(verbose=False)\n\nfrom python_scripts import distinct_pathways\ndpw_pls = distinct_pathways.get_distinct_pathways_routes(dffp)\nqrows = dpw_pls[\"rt_end_cat\"] == \"[Not ended or invalid end reason]\"\ndpw_pls.loc[qrows, \"rt_end_cat\"] = dpw_pls.loc[qrows, \"pl_end_dt\"].isna().map({True: \"[Not ended]\", False: \"Missing data/error\"})\ndpw_pls[\"rt_end_cat\"] = dpw_pls[\"rt_end_cat\"].str.replace(\"To care/hosp.\", \"To care/hospital\")\ndpw_rt_starts = dpw_pls.groupby(\"route_id\").head(1)\ndpw_rt_ends = dpw_pls.groupby(\"route_id\").tail(1)\ndpw_clis = dpw_pls.groupby([\"o_cli_id\"]).head(1)  # 1 duplicate client but first entry has more detailed answers\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams.update({\n    'figure.figsize': (6.2, 4.1),\n    'font.size': 12,\n    'figure.constrained_layout.use': True\n})\n\nexcel_output = {}"
  },
  {
    "objectID": "4.4_durations.html#durations-rq4",
    "href": "4.4_durations.html#durations-rq4",
    "title": "4.4 Results - Durations",
    "section": "Durations (RQ4)",
    "text": "Durations (RQ4)\n\nFigure 4.7: Route durations\n\nCode\n\n\nCode\nimport numpy as np\nimport seaborn as sns\nimport seaborn.objects as so\nsns.set()\n# Set up data\n#############\ndurations = dpw_pls.set_index(\"route_id\")[[\"dur\", \"pl_start_dt\"]]\ndurations[\"dur_days\"] = durations[\"dur\"].dt.days\ndurations[\"dur_days\"] = durations[\"dur_days\"].fillna(1 + (distinct_pathways.dpw_end_dt - durations.pl_start_dt).dt.days)\ndurations = durations.drop(columns=[\"dur\", \"pl_start_dt\"])\nhist_data = (\n    durations.groupby(level=0).dur_days.sum().to_frame()\n    .join(dpw_rt_ends.set_index(\"route_id\")[\"pl_end_dt\"].notna().rename(\"ended\").astype(\"category\")))\nhist_data[\"ended\"] = pd.Categorical(hist_data[\"ended\"], categories=[True, False], ordered=True)\nhist_data[\"dur_years\"] = hist_data[\"dur_days\"] / 365.25\n# Utility function to add quantile markers\nhist_quantiles = hist_data.drop(columns=\"ended\").quantile([0.10, 0.90])  # To be used as markers later\ncolours = sns.color_palette(as_cmap=False)\ndef add_quantiles(p, field, x_limits, y_limits):\n    for q, row in hist_quantiles.iterrows():\n        pct = f\"{100 * q:.0f}%\"\n        x = row[field]\n        p = p.add(so.Line(linewidth=0.7, linestyle=(10, 6), alpha=0.35, color=colours[4]),\n                  data=pd.DataFrame({\"x\": [x, x], \"y\": y_limits}),\n                  x=\"x\", y=\"y\")\n        p = p.add(so.Text({\"clip_on\": False}, valign=\"bottom\", alpha=0.7, color=colours[4], fontsize=9, offset=0),\n                  data=pd.DataFrame({\"x\": [x], \"y\": [y_limits[1]], \"text\": [pct]}),\n                  x=\"x\", y=\"y\", text=\"text\")\n    p = p.add(so.Text({\"clip_on\": False}, valign=\"bottom\", halign=\"right\", alpha=0.7, color=colours[4], fontsize=9, offset=0),\n                data=pd.DataFrame({\"x\": [x_limits[1]], \"y\": [y_limits[1]], \"text\": \"percentile\"}),\n                x=\"x\", y=\"y\", text=\"text\")\n    return p\n# Generate human-readable units and tick positions for log timescales\n#####################################################################\ndays_logunits = {\"day\": 1, \"week\": 7, \"month\": 365.25/12, \"year\": 365.25}\ndays_loglists = {\n    \"days\": [1, 2, 4],\n    \"weeks\": [1, 2],\n    \"months\": [1, 2, 4, 8],\n    \"years\": [1, 2, 4, 8, 16]\n}\ndays_logscale = []\ndays_loglabels_u = []\ndays_loglabels_full = []\ndays_loglabels_grp = []\nfor u, l in days_loglists.items():\n    days_logscale.extend(days_logunits[u[:-1]] * i for i in l)\n    days_loglabels_u.extend(l)\n    days_loglabels_full.extend(f\"{i} {u if i &gt; 1 else u[:-1]}\" for i in l)\n    days_loglabels_grp.append(u)\ndays_logformatter = matplotlib.ticker.FixedFormatter(days_loglabels_u)\n# Calculate positions of separators between groups for log unit labels\ndays_logsep = []\nfor (a_u, a_l), (b_u, b_l) in zip(list(days_loglists.items())[:-1], list(days_loglists.items())[1:]):\n    a_end = days_logunits[a_u[:-1]] * a_l[-1]\n    b_start = days_logunits[b_u[:-1]] * b_l[0]\n    log_midpoint = 10 ** ((np.log10(a_end) + np.log10(b_start))/2)\n    days_logsep.append(log_midpoint)\n# Calculate positions of group labels for log units\ndays_loggrp_edges = [0.8] + days_logsep + [30 * days_logunits[\"year\"]]\ndays_logpos_grp = list(10 ** ((np.log10(a) + np.log10(b))/2) for a, b in zip(days_loggrp_edges[:-1], days_loggrp_edges[1:]))\n# Set up two subplots\n#####################\nf, axs = plt.subplots(nrows=2, figsize=(6.2, 2*4.1), dpi=150)\n# Plot the log scale chart\n##########################\nax = axs[1]\nlimits = {\"x\": (0.7, 10**4), \"y\": (0, 831)}\nplt.subplots_adjust(right=0.95, top=0.98, bottom=0.09, hspace=0.3)\np = (\n    so.Plot(data=hist_data, x=\"dur_days\")\n    .label(x=\"Duration (log scale)\", y=\"Routes\")\n    .add(so.Bars(), so.Hist(bins=20), so.Stack(), color=\"ended\", legend=False)\n    .scale(x=so.Continuous(trans=\"log\").tick(at=days_logscale).label(formatter=days_logformatter), color=so.Nominal(order=[True, False]))\n    .limit(x=limits[\"x\"], y=limits[\"y\"])\n)\n# Add extra readable unit labels (rotated 90 degrees) at the top\np = p.add(\n        so.Text({\"rotation\": 90, \"rotation_mode\": \"anchor\"}, color=\".7\", fontsize=8, halign=\"right\", valign=\"center\", offset=0),\n        data=pd.DataFrame({\"x\": days_logscale, \"y\": [limits[\"y\"][1]-15] * len(days_logscale), \"text\": days_loglabels_full}),\n        x=\"x\", y=\"y\", text=\"text\", legend=False\n)\n# Add quantile indicators\np = add_quantiles(p, \"dur_days\", limits[\"x\"], limits[\"y\"])\np = p.on(ax).plot()\nfor line in ax.get_lines():\n    line.zorder=1.1\n# Lines between unit groups\nax.vlines(days_logsep, -0.04, -0.15, color=\"black\", lw=0.5, clip_on=False, transform=ax.get_xaxis_transform())\n# Grouped unit labels\nfor pos, text in zip(days_logpos_grp, days_loglabels_grp):\n    ax.text(pos, -0.14, text, ha=\"center\", clip_on=False, transform=ax.get_xaxis_transform())\n# Move x-axis label down\nax.xaxis.labelpad = 20\n# Add rug plot\nsns.rugplot(ax=ax, data=hist_data, x=\"dur_days\", hue=\"ended\", height=-.03, clip_on=False, alpha=0.7, legend=False)\n# Plot the linear scale chart\n#############################\nax = axs[0]\nhist_data_lt_10y = hist_data[hist_data[\"dur_years\"] &lt;= 10]\nlimits = {\"x\": (0, 10.5), \"y\": (0, 2000)}\np = (\n    so.Plot(data=hist_data_lt_10y, x=\"dur_years\")\n    .label(x=\"Duration (linear: years)\", y=\"Routes\")\n    .add(so.Bars(), so.Hist(binwidth=0.5), so.Stack(), color=\"ended\", legend=False)\n    .scale(x=so.Continuous().tick(every=1).label(like=\"{x:.0f}\"), color=so.Nominal(order=[True, False]))\n    .limit(x=limits[\"x\"], y=limits[\"y\"])\n    .add(\n        so.Text({\"rotation\": 90, \"rotation_mode\": \"anchor\"}, color=\".7\", fontsize=9, halign=\"left\", valign=\"top\", offset=5),\n        data=pd.DataFrame({\"x\": [10], \"y\": [100], \"text\": [\"2 routes over 10 years not shown\"]}),\n        x=\"x\", y=\"y\", text=\"text\", legend=False)\n)\np = add_quantiles(p, \"dur_years\", limits[\"x\"], limits[\"y\"])\np = p.on(ax).plot()\nsns.rugplot(ax=ax, data=hist_data_lt_10y, x=\"dur_years\", hue=\"ended\", height=-.03, clip_on=False, alpha=0.7, legend=False)\n# Add legend\ncolours = sns.color_palette(as_cmap=False)\nT = matplotlib.patches.Patch(facecolor=colours[0], edgecolor=\"white\", alpha=0.8, label=\"Ended\")\nF = matplotlib.patches.Patch(facecolor=colours[1], edgecolor=\"white\", alpha=0.8, label=\"Current\")\nax.legend(handles=[F, T], loc=\"upper right\")\n# Output the chart\n##################\nfig_4_7 = \"img_output/Figure_4.7.svg\"\nplt.savefig(fig_4_7)\n\n\n\n\nFigure 4.7\n\nNotes: 3,755 people; 5,072 routes. 10% at 35 days, 90% at 3.08 years. Descriptive statistics are in Table A.6.\n\n\nTable A.6\n\n\nCode\ntbl_data = hist_data.copy()\n# tbl_data = hist_data[[\"ended\", \"dur_years\"]]\ntbl_data[\"ended\"] = hist_data[\"ended\"].map({True: \"Ended\", False: \"Current\"})\npercentiles = [0.1, 0.5, 0.9]\nta6 = (\n    pd.concat([\n        tbl_data.groupby(\"ended\", observed=True).describe(percentiles=percentiles),\n        tbl_data.describe(percentiles=percentiles).T.assign(ended=\"All\").set_index(\"ended\", append=True).stack().unstack(level=[0,2])\n    ])\n)\nta6 = ta6.astype(\"object\")\nint_cols = {\"dur_days\": [\"count\", \"min\", \"max\"], \"dur_years\": [\"count\"]}\nfloat_cols = {k: ta6.columns.levels[1].difference(v) for k, v in int_cols.items()}\nfloat_prec = {\"dur_days\": 1, \"dur_years\": 3}\nfor dt in [\"dur_days\", \"dur_years\"]:\n    fp = float_prec[dt]\n    ta6.loc[:, (dt, float_cols[dt])] = (ta6.loc[:, (dt, float_cols[dt])].map(lambda x: f\"{x:,.{fp}f}\"))\n    ta6.loc[:, (dt, int_cols[dt])] = (ta6.loc[:, (dt, int_cols[dt])].map(lambda x: f\"{x:,.0f}\"))\nta6 = (\n    ta6.T.reindex((a, b)\n                    for a in [\"dur_years\", \"dur_days\"]\n                    for b in [x for x in ta6[\"dur_days\"].columns if x != \"count\"] + [\"count\"]).T\n    .rename(columns={\"50%\": \"median\"})\n)\nta6 = pd.concat([ta6[\"dur_years\"], ta6[\"dur_days\"]], keys=[\"Years\", \"Days\"])\ndur_6y = tbl_data[tbl_data[\"dur_years\"] &gt; 6].ended.value_counts().to_frame()\ndur_0d = tbl_data[tbl_data[\"dur_days\"] == 0].ended.value_counts().to_frame()\nexcel_output[\"Table A.6: Descriptive statistics for route durations by whether ended/current\"] = ta6\ndisplay(ta6)\n\n\n\n\n\n\n\n\n\n\nmean\nstd\nmin\n10%\nmedian\n90%\nmax\ncount\n\n\n\nended\n\n\n\n\n\n\n\n\n\n\n\n\nYears\nEnded\n1.115\n1.223\n0.000\n0.090\n0.713\n2.669\n20.118\n4,334\n\n\nCurrent\n2.118\n2.129\n0.003\n0.151\n1.269\n5.472\n9.919\n738\n\n\nAll\n1.261\n1.436\n0.000\n0.096\n0.769\n3.080\n20.118\n5,072\n\n\nDays\nEnded\n407.2\n446.6\n0\n33.0\n260.5\n975.0\n7,348\n4,334\n\n\nCurrent\n773.6\n777.7\n1\n55.0\n463.5\n1,998.8\n3,623\n738\n\n\nAll\n460.5\n524.4\n0\n35.0\n281.0\n1,124.8\n7,348\n5,072\n\n\n\n\n\n\n\n\n\n\nFigure 4.8: Route durations by end reason\n\nCode\n\n\nCode\nimport numpy as np\nimport seaborn as sns\nimport seaborn.objects as so\nsns.set()\n# Set up data\n#############\ndurations = dpw_pls.set_index(\"route_id\")[[\"dur\", \"pl_start_dt\"]]\ndurations[\"dur_days\"] = durations[\"dur\"].dt.days\ndurations[\"dur_days\"] = durations[\"dur_days\"].fillna(1 + (distinct_pathways.dpw_end_dt - durations.pl_start_dt).dt.days)\ndurations = durations.drop(columns=[\"dur\", \"pl_start_dt\"])\nhist_data = (\n    durations.groupby(level=0).dur_days.sum().to_frame()\n    .join(dpw_rt_ends.set_index(\"route_id\")[\"pl_end_dt\"].notna().rename(\"ended\").astype(\"category\"))\n    .join(dpw_rt_ends.set_index(\"route_id\")[[\"rt_end_cat\", \"pl_end_dt\"]])\n)\nhist_data[\"ended\"] = pd.Categorical(hist_data[\"ended\"], categories=[True, False], ordered=True)\nhist_data[\"dur_years\"] = hist_data[\"dur_days\"] / 365.25\nqrows = hist_data[\"rt_end_cat\"] == \"[Not ended or invalid end reason]\"\nhist_data.loc[qrows, \"rt_end_cat\"] = hist_data.loc[qrows, \"pl_end_dt\"].isna().map({True: \"[Not ended]\", False: \"Missing data/error\"})\nhist_data = hist_data.drop(columns=\"pl_end_dt\")\ncolours = sns.color_palette(as_cmap=False)\n# Calculate positions of group labels for log units\ndays_loggrp_edges = [0.8] + days_logsep + [30 * days_logunits[\"year\"]]\ndays_logpos_grp = list(10 ** ((np.log10(a) + np.log10(b))/2) for a, b in zip(days_loggrp_edges[:-1], days_loggrp_edges[1:]))\n# Calculate order for facets\nfacet_order = (hist_data.groupby(\"rt_end_cat\").size().to_frame().reset_index()\n               .sort_values(0, ascending=False)[\"rt_end_cat\"].to_list())\n# Generate human-readable units and tick positions for log timescales\n#####################################################################\ndays_logunits = {\"day\": 1, \"week\": 7, \"month\": 365.25/12, \"year\": 365.25}\ndays_loglists = {\n    \"weeks\": [1],\n    \"months\": [1, 4],\n    \"years\": [1, 3, 9]\n}\ndays_logscale = []\ndays_loglabels_u = []\ndays_loglabels_full = []\ndays_loglabels_grp = []\nfor u, l in days_loglists.items():\n    days_logscale.extend(days_logunits[u[:-1]] * i for i in l)\n    # days_loglabels_u.extend(l)\n    days_loglabels_u.extend(f\"{x}{u[0]}\" for x in l)\n    days_loglabels_full.extend(f\"{i} {u if i &gt; 1 else u[:-1]}\" for i in l)\n    days_loglabels_grp.append(u)\ndays_logformatter = matplotlib.ticker.FixedFormatter(days_loglabels_u)\n# Plot log scale charts\n#######################\nlimits = {\"x\": (0.014*365.25, 10*365.25), \"y\": (None, 100)}\nfig_4_8_a = \"img_output/Figure_4.8_a.svg\"\np = (\n    so.Plot(data=hist_data, x=\"dur_days\")\n    # .label(x=\"Duration (log scale)\", y=\"Routes\")\n    .add(so.Bars(), so.Hist(bins=20), so.Stack(), color=\"ended\", legend=False)\n    .scale(x=so.Continuous(trans=\"log\").tick(at=days_logscale).label(formatter=days_logformatter),\n           color=so.Nominal(order=[True, False]))\n    .facet(\"rt_end_cat\", wrap=4, order=facet_order)\n    .limit(x=limits[\"x\"])\n    .save(fig_4_8_a)\n)\nfig_4_8_b = \"img_output/Figure_4.8_b.svg\"\np = (\n    so.Plot(data=hist_data, x=\"dur_days\")\n    # .label(x=\"Duration (log scale)\", y=\"Routes\")\n    .add(so.Bars(), so.Hist(bins=20), so.Stack(), color=\"ended\", legend=False)\n    .scale(x=so.Continuous(trans=\"log\").tick(at=days_logscale).label(formatter=days_logformatter),\n           color=so.Nominal(order=[True, False]))\n    .facet(\"rt_end_cat\", wrap=4, order=facet_order)\n    .limit(x=limits[\"x\"], y=limits[\"y\"])\n    .save(fig_4_8_b)\n)\n\n\n\n\nFigure 4.8\n\nIncreased-scale y-axis (zoomed in):\n\nNote: Descriptive statistics are in Table A.7.\n\n\nTable A.7\n\n\nCode\ntbl_data = hist_data.copy()\n# tbl_data = hist_data[[\"ended\", \"dur_years\"]]\ntbl_data[\"ended\"] = hist_data[\"ended\"].map({True: \"Ended\", False: \"Current\"})\npercentiles = [0.1, 0.5, 0.9]\nta7 = (\n    pd.concat([\n        (tbl_data.groupby(\"rt_end_cat\", observed=True).describe(percentiles=percentiles)\n         .sort_values((\"dur_days\", \"mean\"), ascending=False)),\n        tbl_data.describe(percentiles=percentiles).T.assign(rt_end_cat=\"All\").set_index(\"rt_end_cat\", append=True).stack().unstack(level=[0,2])\n    ])\n)\nta7 = ta7.astype(\"object\")\nint_cols = {\"dur_days\": [\"count\", \"min\", \"max\"], \"dur_years\": [\"count\"]}\nfloat_cols = {k: ta7.columns.levels[1].difference(v) for k, v in int_cols.items()}\nfloat_prec = {\"dur_days\": 1, \"dur_years\": 3}\nfor dt in [\"dur_days\", \"dur_years\"]:\n    fp = float_prec[dt]\n    ta7.loc[:, (dt, float_cols[dt])] = (ta7.loc[:, (dt, float_cols[dt])].map(lambda x: f\"{x:,.{fp}f}\"))\n    ta7.loc[:, (dt, int_cols[dt])] = (ta7.loc[:, (dt, int_cols[dt])].map(lambda x: f\"{x:,.0f}\"))\nta7 = (\n    ta7.T.reindex((a, b)\n                    for a in [\"dur_years\", \"dur_days\"]\n                    for b in [x for x in ta7[\"dur_days\"].columns if x != \"count\"] + [\"count\"]).T\n    .rename(columns={\"50%\": \"median\"})\n)\nta7 = pd.concat([ta7[\"dur_years\"], ta7[\"dur_days\"]], keys=[\"Years\", \"Days\"])\nexcel_output[\"Table A.7: Descriptive statistics for route durations by end reasons\"] = ta7\ndisplay(ta7)\n\n\n\n\n\n\n\n\n\n\nmean\nstd\nmin\n10%\nmedian\n90%\nmax\ncount\n\n\n\nrt_end_cat\n\n\n\n\n\n\n\n\n\n\n\n\nYears\n[Not ended]\n2.118\n2.129\n0.003\n0.151\n1.269\n5.472\n9.919\n738\n\n\nTo social housing\n1.877\n1.265\n0.027\n0.482\n1.643\n3.569\n7.291\n999\n\n\nDied\n1.757\n2.299\n0.008\n0.151\n1.054\n3.595\n20.118\n117\n\n\nTo private rented\n1.205\n1.053\n0.000\n0.199\n0.883\n2.471\n5.591\n278\n\n\nTo care/hospital\n1.190\n1.581\n0.003\n0.077\n0.665\n2.919\n12.394\n171\n\n\nTo external supported\n1.079\n1.246\n0.011\n0.090\n0.665\n2.494\n7.294\n167\n\n\nOther\n0.928\n0.956\n0.000\n0.095\n0.575\n2.225\n5.172\n289\n\n\nEvicted\n0.923\n1.101\n0.000\n0.118\n0.537\n2.200\n7.885\n867\n\n\nMissing data/error\n0.881\n1.126\n0.000\n0.047\n0.444\n2.317\n5.481\n95\n\n\nTo friends/family\n0.729\n0.734\n0.003\n0.060\n0.490\n1.789\n3.751\n376\n\n\nAbandoned\n0.624\n0.855\n0.000\n0.036\n0.268\n1.691\n6.486\n639\n\n\nCustody\n0.616\n0.781\n0.000\n0.051\n0.337\n1.577\n5.325\n336\n\n\nAll\n1.261\n1.436\n0.000\n0.096\n0.769\n3.080\n20.118\n5,072\n\n\nDays\n[Not ended]\n773.6\n777.7\n1\n55.0\n463.5\n1,998.8\n3,623\n738\n\n\nTo social housing\n685.4\n462.1\n10\n176.2\n600.0\n1,303.6\n2,663\n999\n\n\nDied\n641.7\n839.6\n3\n55.0\n385.0\n1,313.2\n7,348\n117\n\n\nTo private rented\n440.3\n384.5\n0\n72.7\n322.5\n902.6\n2,042\n278\n\n\nTo care/hospital\n434.8\n577.5\n1\n28.0\n243.0\n1,066.0\n4,527\n171\n\n\nTo external supported\n394.1\n455.0\n4\n33.0\n243.0\n910.8\n2,664\n167\n\n\nOther\n339.1\n349.3\n0\n34.6\n210.0\n812.6\n1,889\n289\n\n\nEvicted\n337.3\n402.3\n0\n43.0\n196.0\n803.6\n2,880\n867\n\n\nMissing data/error\n321.6\n411.3\n0\n17.0\n162.0\n846.2\n2,002\n95\n\n\nTo friends/family\n266.2\n268.0\n1\n22.0\n179.0\n653.5\n1,370\n376\n\n\nAbandoned\n227.8\n312.3\n0\n13.0\n98.0\n617.6\n2,369\n639\n\n\nCustody\n225.1\n285.2\n0\n18.5\n123.0\n576.0\n1,945\n336\n\n\nAll\n460.5\n524.4\n0\n35.0\n281.0\n1,124.8\n7,348\n5,072"
  },
  {
    "objectID": "4.4_durations.html#tables-in-an-excel-file",
    "href": "4.4_durations.html#tables-in-an-excel-file",
    "title": "4.4 Results - Durations",
    "section": "Tables in an Excel file",
    "text": "Tables in an Excel file\n\nCode\nimport os\nsheetname = \"Sheet1\"\nqmdfile = os.getenv(\"QUARTO_DOCUMENT_FILE\")\nfilename = \"img_output/\"+qmdfile[:-4]+\".xlsx\"\nwith pd.ExcelWriter(filename) as writer:\n    next_row = 0\n    for k, v in excel_output.items():\n        pd.DataFrame([k]).to_excel(writer, sheet_name=sheetname, header=False, index=False, startrow=next_row)\n        next_row += 1\n        v.to_excel(writer, sheet_name=sheetname, startrow=next_row, float_format=\"%.1f\")\n        next_row += (\n            (1 if not isinstance(v.columns, pd.MultiIndex) else 1 + len(v.columns.levels))\n            + len(v) + 1)\nprint(f\"[Excel file](./{filename})\")\n\nExcel file"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BSHARP",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nFeb 6, 2026\n\n\n4.1 Results - Outcomes\n\n\nDavid Ingerslev\n\n\n\n\n\n\nFeb 8, 2026\n\n\n4.2 Results - Capacity and throughput\n\n\nDavid Ingerslev\n\n\n\n\n\n\nFeb 8, 2026\n\n\n4.3 Results - Number of routes\n\n\nDavid Ingerslev\n\n\n\n\n\n\nFeb 10, 2026\n\n\n4.4 Results - Durations\n\n\nDavid Ingerslev\n\n\n\n\n\n\nFeb 10, 2026\n\n\n4.5 Results - Returns\n\n\nDavid Ingerslev\n\n\n\n\n\n\nFeb 10, 2026\n\n\n4.6 Results - Moves between services\n\n\nDavid Ingerslev\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "4.5_returns.html",
    "href": "4.5_returns.html",
    "title": "4.5 Results - Returns",
    "section": "",
    "text": "Code\n# Setup code\nimport pandas as pd\nfrom python_scripts import setup\nfrom python_scripts import services\nfrom python_scripts import helper\ndf, dffp = setup.setup(verbose=False)\n\nfrom python_scripts import distinct_pathways\ndpw_pls = distinct_pathways.get_distinct_pathways_routes(dffp)\nqrows = dpw_pls[\"rt_end_cat\"] == \"[Not ended or invalid end reason]\"\ndpw_pls.loc[qrows, \"rt_end_cat\"] = dpw_pls.loc[qrows, \"pl_end_dt\"].isna().map({True: \"[Not ended]\", False: \"Missing data/error\"})\ndpw_pls[\"rt_end_cat\"] = dpw_pls[\"rt_end_cat\"].str.replace(\"To care/hosp.\", \"To care/hospital\")\ndpw_rt_starts = dpw_pls.groupby(\"route_id\").head(1)\ndpw_rt_ends = dpw_pls.groupby(\"route_id\").tail(1)\ndpw_clis = dpw_pls.groupby([\"o_cli_id\"]).head(1)  # 1 duplicate client but first entry has more detailed answers\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams.update({\n    'figure.figsize': (6.2, 4.1),\n    'font.size': 12,\n    'figure.constrained_layout.use': True\n})\n\nexcel_output = {}"
  },
  {
    "objectID": "4.5_returns.html#returns-rq5",
    "href": "4.5_returns.html#returns-rq5",
    "title": "4.5 Results - Returns",
    "section": "Returns (RQ5)",
    "text": "Returns (RQ5)\n\nTable 4.3: Returns at periods of time after routes ended (per route)\n\n\nCode\nstable_periods = {x: f\"after_rt_ret_within_{x}\" for x in distinct_pathways.stable_offsets.keys()}\nstable_period_max_end_dts = {x: distinct_pathways.dpw_end_dt - distinct_pathways.stable_offsets[x]\n                             for x in distinct_pathways.stable_offsets.keys()}\nroute_end_grp = (dpw_rt_ends[dpw_rt_ends[\"pl_end_dt\"].notnull() & (dpw_rt_ends[\"rt_end_cat\"] != \"Died\")]\n                 .assign(All=\"All\").groupby(\"All\"))\nroute_outcomes = route_end_grp.size().sort_values(ascending=False).rename((\"outcomes\", \"n\")).to_frame()\nroute_outcomes[(\"outcomes\", \"%\")] = (100*route_outcomes[(\"outcomes\", \"n\")]\n                                     / route_outcomes[(\"outcomes\", \"n\")].sum())\nfor k, v in stable_periods.items():\n    route_outcomes[k, f\"&lt;t\"] = (route_end_grp[\"pl_end_dt\"]\n                                .apply(lambda x: (x &gt;= stable_period_max_end_dts[k]).sum()).astype(\"Int64\"))\n    route_outcomes[k, f\"&gt;=t\"] = (route_end_grp[\"pl_end_dt\"]\n                                 .apply(lambda x: (x &lt; stable_period_max_end_dts[k]).sum()).astype(\"Int64\"))\n    route_outcomes[k, f\"&lt;t ret\"] = (route_end_grp\n                                    .apply(lambda x: ((x[\"pl_end_dt\"] &gt;= stable_period_max_end_dts[k])\n                                                      & (x[v] == \"Yes\")).sum()).astype(\"Int64\"))\n    # route_outcomes[k, f\"&lt;t\"] = route_end_grp[v].apply(lambda x: (x == \"Not yet...\").sum()).astype(\"Int64\")\n    for outcome in [\"Yes\", \"No\"]:\n        route_outcomes[k, outcome] = (route_end_grp\n                                      .apply(lambda x: ((x[\"pl_end_dt\"] &lt; stable_period_max_end_dts[k])\n                                                        & (x[v] == outcome)).sum()).astype(\"Int64\"))\n    route_outcomes[k, \"Y+N\"] = (route_outcomes[k, \"Yes\"]\n                                + route_outcomes[k, \"No\"])\n    route_outcomes[k, \"% Y/(Y+N)\"] = (route_outcomes[k, \"Yes\"]\n                                      .mul(100).div(route_outcomes[k, \"Yes\"]\n                                                    + route_outcomes[k, \"No\"]))\n    route_outcomes[k, \"% No/sum(n)\"] = (route_outcomes[k, \"No\"]\n                                        .mul(100).div(route_outcomes[(\"outcomes\", \"n\")].sum()))\ntbl_periods = route_outcomes.astype(\"object\").iloc[:, 2:].stack()\nt4_3 = route_outcomes.astype(\"object\").iloc[:, 2:].stack().loc[\"All\"].loc[[\"&gt;=t\", \"Yes\", \"% Y/(Y+N)\"]]\nt4_3.loc[\"% N/(Y+N)\"] = 100 - t4_3.loc[\"% Y/(Y+N)\"]\nt4_3 = t4_3.rename(index={\"&gt;=t\": \"Eligible routes\",\n                          \"Yes\": \"Subsequent returns\",\n                          \"% Y/(Y+N)\": \"% returned\",\n                          \"% N/(Y+N)\": \"% not returned\"})\nwith pd.option_context(\"display.float_format\", \"{:,.1f}\".format):\n    display(t4_3)\nexcel_output[\"Table 4.3: Returns at periods of time after routes ended (per route)\"] = t4_3\n\n\n\n\n\n\n\n\n\n90d\n6m\n15m\n18m\n2y\n5y\n\n\n\n\nEligible routes\n4077\n3959\n3632\n3527\n3275\n1617\n\n\nSubsequent returns\n354\n607\n914\n961\n970\n625\n\n\n% returned\n8.7\n15.3\n25.2\n27.2\n29.6\n38.7\n\n\n% not returned\n91.3\n84.7\n74.8\n72.8\n70.4\n61.3\n\n\n\n\n\n\n\nNotes: 1. Return = new route that started before 30/04/2025.\n\n\nTable 4.4: Returns at periods of time after people’s first routes ended (per person)\n\n\nCode\nstable_periods = {x: f\"after_rt_ret_within_{x}\" for x in distinct_pathways.stable_offsets.keys()}\nstable_period_max_end_dts = {x: distinct_pathways.dpw_end_dt - distinct_pathways.stable_offsets[x]\n                             for x in distinct_pathways.stable_offsets.keys()}\npl_before_dpw_start = dffp.loc[(dffp[\"pl_start_dt\"] &lt; distinct_pathways.dpw_start_dt), \"o_cli_id\"].unique()\ndpw_clis_before_start = dpw_clis.loc[dpw_clis[\"o_cli_id\"].isin(pl_before_dpw_start), \"o_cli_id\"]\nfirst_dpw_routes = dpw_pls.groupby(\"o_cli_id\").head(1)[\"route_id\"]\nfirst_route_end_pls = (dpw_pls[dpw_pls[\"route_id\"].isin(first_dpw_routes)]\n                       .groupby(\"route_id\").tail(1)[lambda x: x[\"pl_end_dt\"].notnull() & (x[\"rt_end_cat\"] != \"Died\")]\n                       .assign(Group=lambda x: x[\"o_cli_id\"].isin(dpw_clis_before_start).map({True: \"Prev\", False: \"New\"})))\nfirst_route_end_grp = pd.concat([first_route_end_pls, first_route_end_pls.assign(Group=\"All\")]).groupby(\"Group\")\nfirst_route_outcomes = first_route_end_grp.size().sort_values(ascending=False).rename((\"outcomes\", \"n\")).to_frame()\nfirst_route_outcomes[(\"outcomes\", \"%\")] = (100*first_route_outcomes[(\"outcomes\", \"n\")]\n                                           / first_route_outcomes.loc[\"All\", (\"outcomes\", \"n\")])\nfor k, v in stable_periods.items():\n    first_route_outcomes[k, f\"&lt;t\"] = (first_route_end_grp[\"pl_end_dt\"]\n                                      .apply(lambda x: (x &gt;= stable_period_max_end_dts[k]).sum()).astype(\"Int64\"))\n    first_route_outcomes[k, f\"&gt;=t\"] = (first_route_end_grp[\"pl_end_dt\"]\n                                       .apply(lambda x: (x &lt; stable_period_max_end_dts[k]).sum()).astype(\"Int64\"))\n    first_route_outcomes[k, f\"&lt;t ret\"] = (first_route_end_grp\n                                          .apply(lambda x: ((x[\"pl_end_dt\"] &gt;= stable_period_max_end_dts[k])\n                                                            & (x[v] == \"Yes\")).sum()).astype(\"Int64\"))\n    # first_route_outcomes[k, f\"&lt;t\"] = first_route_end_grp[v].apply(lambda x: (x == \"Not yet...\").sum()).astype(\"Int64\")\n    for outcome in [\"Yes\", \"No\"]:\n        first_route_outcomes[k, outcome] = (first_route_end_grp\n                                            .apply(lambda x: ((x[\"pl_end_dt\"] &lt; stable_period_max_end_dts[k])\n                                                              & (x[v] == outcome)).sum()).astype(\"Int64\"))\n    first_route_outcomes[k, \"Y+N\"] = (first_route_outcomes[k, \"Yes\"]\n                                      + first_route_outcomes[k, \"No\"])\n    first_route_outcomes[k, \"% Y/(Y+N)\"] = (first_route_outcomes[k, \"Yes\"]\n                                            .mul(100).div(first_route_outcomes[k, \"Yes\"]\n                                                          + first_route_outcomes[k, \"No\"]))\n    first_route_outcomes[k, \"% No/sum(n)\"] = (first_route_outcomes[k, \"No\"]\n                                              .mul(100).div(first_route_outcomes[(\"outcomes\", \"n\")].sum()))\n\n\ntbl_n = first_route_outcomes.iloc[:, :2].sort_index(ascending=False)\ntbl_periods = first_route_outcomes.astype(\"object\").iloc[:, 2:].stack().sort_index(level=0, ascending=False, sort_remaining=False)\nt4_4 = tbl_periods.loc[\"All\"].loc[[\"&gt;=t\", \"Yes\", \"% Y/(Y+N)\"]]\nt4_4.loc[\"% N/(Y+N)\"] = 100 - t4_4.loc[\"% Y/(Y+N)\"]\nt4_4 = t4_4.rename(index={\"&gt;=t\": \"Eligible first routes\",\n                          \"Yes\": \"Subsequent returns\",\n                          \"% Y/(Y+N)\": \"% returned\",\n                          \"% N/(Y+N)\": \"% not returned\"})\nwith pd.option_context(\"display.float_format\", \"{:,.1f}\".format):\n    display(t4_4)\n\n\n\n\n\n\n\n\n\n90d\n6m\n15m\n18m\n2y\n5y\n\n\n\n\nEligible first routes\n3039\n2957\n2738\n2661\n2508\n1387\n\n\nSubsequent returns\n216\n359\n562\n586\n615\n468\n\n\n% returned\n7.1\n12.1\n20.5\n22.0\n24.5\n33.7\n\n\n% not returned\n92.9\n87.9\n79.5\n78.0\n75.5\n66.3\n\n\n\n\n\n\n\n\n\nFigure 4.9: Returns at periods of time after exits\n\n\nCode\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nperiodMult = {\"d\": 1, \"m\": 365.25/12, \"y\": 365.25}\nperiodYears = {x: int(x[:-1]) * periodMult[x[-1]] / periodMult[\"y\"] for x in distinct_pathways.stable_offsets.keys()}\nplotdata = (\n    pd.concat([\n        t4_3.loc[\"% returned\"].to_frame()\n        .assign(years=lambda x: x.index.map(periodYears), grp=\"Per route (all exits)\")\n        .reset_index(),\n        t4_4.loc[\"% returned\"].to_frame()\n        .assign(years=lambda x: x.index.map(periodYears), grp=\"Per person (first exits)\")\n        .reset_index()\n    ])\n)\ngrps = plotdata[\"grp\"].unique()\nplotdata = (\n    pd.concat([pd.DataFrame({\"index\": \"\", \"% returned\": 0, \"years\": 0, \"grp\": grps}, index=[\"\"]*len(grps)), plotdata])\n    .reset_index(drop=True))\np = (\n    so.Plot(data=plotdata, y=\"% returned\", x=\"years\", text=\"index\")\n    .facet(col=\"grp\")\n    .label(x=\"years since exit\")\n    .add(so.Dot(), data=plotdata[plotdata[\"index\"] != \"\"])\n    .add(so.Line())\n    .add(so.Area(edgewidth=0))\n    .add(so.Text(halign=\"left\", valign=\"top\"))\n    .limit(x=(0, 5.5), y=(0, 40))\n    .scale(x=so.Continuous().tick(minor=1))\n    .theme({\"axes.grid.which\": \"both\"})\n    .layout(size=(6.2, 3.6), engine=\"constrained\")\n)\nfig_4_9 = \"img_output/Figure_4.9.svg\"\np.save(fig_4_9)\npass\n\n\n\nNote: Data tables are Table 4.3 and Table 4.4.\n\n\nTable A.8: Returns at periods of time after exit by end reason\n\n\nCode\n# Generate table\nstable_periods = {x: f\"after_rt_ret_within_{x}\" for x in distinct_pathways.stable_offsets.keys()}\nstable_period_max_end_dts = {x: distinct_pathways.dpw_end_dt - distinct_pathways.stable_offsets[x]\n                             for x in distinct_pathways.stable_offsets.keys()}\nroute_end_grp = (dpw_rt_ends[dpw_rt_ends[\"pl_end_dt\"].notnull() & (dpw_rt_ends[\"rt_end_cat\"] != \"Died\")]\n                 .assign(All=\"All\").groupby(\"rt_end_cat\"))\nroute_outcomes = route_end_grp.size().sort_values(ascending=False).rename((\"outcomes\", \"n\")).to_frame()\nroute_outcomes[(\"outcomes\", \"%\")] = (100*route_outcomes[(\"outcomes\", \"n\")]\n                                     / route_outcomes[(\"outcomes\", \"n\")].sum())\nfor k, v in stable_periods.items():\n    route_outcomes[k, f\"Eligible (n)\"] = (route_end_grp[\"pl_end_dt\"]\n                                 .apply(lambda x: (x &lt; stable_period_max_end_dts[k]).sum()).astype(\"Int64\"))\n    for outcome in [\"Yes\", \"No\"]:\n        route_outcomes[k, outcome] = (route_end_grp\n                                      .apply(lambda x: ((x[\"pl_end_dt\"] &lt; stable_period_max_end_dts[k])\n                                                        & (x[v] == outcome)).sum()).astype(\"Int64\"))\n    route_outcomes[k, \"% returned\"] = (route_outcomes[k, \"Yes\"]\n                                       .mul(100).div(route_outcomes[k, \"Yes\"]\n                                                     + route_outcomes[k, \"No\"]))\n    route_outcomes = route_outcomes.drop(columns=(k, \"No\"))\n    route_outcomes = route_outcomes.rename(columns={\"Yes\": \"Returned (n)\"}, level=1)\nna_cols = [\"[Not ended]\", \"Died\"]\nroute_outcomes = route_outcomes.sort_values((\"outcomes\", \"%\"), ascending=False)\nta8_n = route_outcomes.iloc[:, :2]\nroute_outcomes = route_outcomes.sort_values((\"2y\", \"% returned\"), ascending=True)\nta8_periods = (route_outcomes.astype(\"object\")\n               .loc[[x for x in route_outcomes.index.to_list() if x not in na_cols]]\n               .iloc[:, 2:].stack(sort=False))\nta8 = ta8_periods\nta8.index = ta8.index.set_names((\"End reason\", \"Statistic\"))\nwith pd.option_context(\"display.float_format\", \"{:,.1f}\".format):\n    display(ta8)\n\nexcel_output[\"Table A.8: Returns at periods of time after exit by end reason\"] = ta8\n\n\n\n\n\n\n\n\n\n\n90d\n6m\n15m\n18m\n2y\n5y\n\n\nEnd reason\nStatistic\n\n\n\n\n\n\n\n\n\n\nTo social housing\nEligible (n)\n979\n954\n885\n870\n822\n418\n\n\nReturned (n)\n1\n1\n4\n6\n8\n10\n\n\n% returned\n0.1\n0.1\n0.5\n0.7\n1.0\n2.4\n\n\nTo private rented\nEligible (n)\n273\n267\n239\n234\n224\n103\n\n\nReturned (n)\n1\n5\n9\n10\n16\n12\n\n\n% returned\n0.4\n1.9\n3.8\n4.3\n7.1\n11.7\n\n\nTo friends/family\nEligible (n)\n364\n358\n345\n339\n322\n177\n\n\nReturned (n)\n12\n26\n59\n68\n77\n60\n\n\n% returned\n3.3\n7.3\n17.1\n20.1\n23.9\n33.9\n\n\nMissing data/error\nEligible (n)\n74\n74\n70\n68\n62\n42\n\n\nReturned (n)\n11\n17\n17\n17\n15\n15\n\n\n% returned\n14.9\n23.0\n24.3\n25.0\n24.2\n35.7\n\n\nTo external supported\nEligible (n)\n161\n155\n142\n138\n130\n66\n\n\nReturned (n)\n13\n27\n36\n36\n39\n26\n\n\n% returned\n8.1\n17.4\n25.4\n26.1\n30.0\n39.4\n\n\nOther\nEligible (n)\n275\n266\n232\n227\n213\n96\n\n\nReturned (n)\n34\n48\n61\n61\n71\n42\n\n\n% returned\n12.4\n18.0\n26.3\n26.9\n33.3\n43.8\n\n\nTo care/hospital\nEligible (n)\n163\n154\n139\n138\n127\n65\n\n\nReturned (n)\n27\n42\n51\n53\n50\n31\n\n\n% returned\n16.6\n27.3\n36.7\n38.4\n39.4\n47.7\n\n\nAbandoned\nEligible (n)\n626\n609\n553\n528\n477\n234\n\n\nReturned (n)\n59\n126\n218\n230\n223\n152\n\n\n% returned\n9.4\n20.7\n39.4\n43.6\n46.8\n65.0\n\n\nEvicted\nEligible (n)\n835\n801\n726\n688\n621\n292\n\n\nReturned (n)\n164\n246\n328\n334\n323\n191\n\n\n% returned\n19.6\n30.7\n45.2\n48.5\n52.0\n65.4\n\n\nCustody\nEligible (n)\n327\n321\n301\n297\n277\n124\n\n\nReturned (n)\n32\n69\n131\n146\n148\n86\n\n\n% returned\n9.8\n21.5\n43.5\n49.2\n53.4\n69.4\n\n\n\n\n\n\n\n\n\nFigure 4.10: Return proportions at periods of time after eligible exits by end reason\n\n\nCode\n# Plot chart\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nperiodMult = {\"d\": 1, \"m\": 365.25/12, \"y\": 365.25}\nperiodYears = {x: int(x[:-1]) * periodMult[x[-1]] / periodMult[\"y\"] for x in distinct_pathways.stable_offsets.keys()}\nplotdata = (\n    ta8.unstack(0).loc[\"% returned\"].reset_index(1)\n    .assign(years=lambda x: x.index.map(periodYears))\n    .reset_index()\n)\nzeroes = pd.DataFrame({\"index\": \"\", \"End reason\": plotdata[\"End reason\"].unique(), \"% returned\": 0, \"years\": 0},\n                      index=range(len(plotdata), len(plotdata) + plotdata[\"End reason\"].nunique()))\nplotdata = pd.concat([zeroes, plotdata])\nfacet_order = ta8_n.index.to_list()\np = (\n    so.Plot(data=plotdata, y=\"% returned\", x=\"years\", text=\"index\")\n    .facet(\"End reason\", wrap=4, order=facet_order)\n    .label(x=\"\", y=\"\")\n    .add(so.Dot(), data=plotdata[plotdata[\"index\"] != \"\"])\n    .add(so.Line())\n    .add(so.Area(edgewidth=0))\n    .limit(x=(0, 5), y=(0, None))\n    .scale(x=(so.Continuous()\n              .tick(every=1, minor=0)\n              .label(like=lambda x, pos: f\"{x:.0f}\" if x != 5 else \"5y\")),\n           y=so.Continuous().tick(minor=1).label(unit=(\"\", \"%\")))\n    .theme({\"axes.grid.which\": \"both\"})\n    .layout(size=(7.2, 4.1), engine=\"constrained\")\n)\nfig_4_10 = \"img_output/Figure_4.10.svg\"\np.save(fig_4_10)\npass\n\n\n\nNote: Data table is Table A.8. Figure B.1 shows return and eligible exit counts per end reason."
  },
  {
    "objectID": "4.5_returns.html#tables-in-an-excel-file",
    "href": "4.5_returns.html#tables-in-an-excel-file",
    "title": "4.5 Results - Returns",
    "section": "Tables in an Excel file",
    "text": "Tables in an Excel file\n\nCode\nimport os\nsheetname = \"Sheet1\"\nqmdfile = os.getenv(\"QUARTO_DOCUMENT_FILE\")\nfilename = \"img_output/\"+qmdfile[:-4]+\".xlsx\"\nwith pd.ExcelWriter(filename) as writer:\n    next_row = 0\n    for k, v in excel_output.items():\n        pd.DataFrame([k]).to_excel(writer, sheet_name=sheetname, header=False, index=False, startrow=next_row)\n        next_row += 1\n        v.to_excel(writer, sheet_name=sheetname, startrow=next_row, float_format=\"%.1f\")\n        next_row += (\n            (1 if not isinstance(v.columns, pd.MultiIndex) else 1 + len(v.columns.levels))\n            + len(v) + 1)\nprint(f\"[Excel file](./{filename})\")\n\nExcel file"
  },
  {
    "objectID": "4.3_number_of_routes.html",
    "href": "4.3_number_of_routes.html",
    "title": "4.3 Results - Number of routes",
    "section": "",
    "text": "Code\n# Setup code\nimport pandas as pd\nfrom python_scripts import setup\nfrom python_scripts import services\nfrom python_scripts import helper\ndf, dffp = setup.setup(verbose=False)\n\nfrom python_scripts import distinct_pathways\ndpw_pls = distinct_pathways.get_distinct_pathways_routes(dffp)\nqrows = dpw_pls[\"rt_end_cat\"] == \"[Not ended or invalid end reason]\"\ndpw_pls.loc[qrows, \"rt_end_cat\"] = dpw_pls.loc[qrows, \"pl_end_dt\"].isna().map({True: \"[Not ended]\", False: \"Missing data/error\"})\ndpw_pls[\"rt_end_cat\"] = dpw_pls[\"rt_end_cat\"].str.replace(\"To care/hosp.\", \"To care/hospital\")\ndpw_rt_starts = dpw_pls.groupby(\"route_id\").head(1)\ndpw_rt_ends = dpw_pls.groupby(\"route_id\").tail(1)\ndpw_clis = dpw_pls.groupby([\"o_cli_id\"]).head(1)  # 1 duplicate client but first entry has more detailed answers\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams.update({\n    'figure.figsize': (6.2, 4.1),\n    'font.size': 12,\n    'figure.constrained_layout.use': True\n})\n\nexcel_output = {}"
  },
  {
    "objectID": "4.3_number_of_routes.html#number-of-routes-rq3",
    "href": "4.3_number_of_routes.html#number-of-routes-rq3",
    "title": "4.3 Results - Number of routes",
    "section": "Number of routes (RQ3)",
    "text": "Number of routes (RQ3)\n\nFigure 4.6: Numbers of people who experienced different quantities of routes by whether they were ‘new’ or had returned after previously using services\n\nCode\n\n\nCode\n# Generate Table A.5\nknown_apw = dffp.loc[\n    dffp.svc_type.isin(services.adult_pathways_accom_svc_types)\n    & (dffp.pl_end_dt &lt; distinct_pathways.dpw_start_dt),\n    \"o_cli_id\",\n]\ndpw_pls[\"known_apw\"] = dpw_pls[\"o_cli_id\"].isin(known_apw).map({False: \"New\", True: \"Returned\"})\ndpw_pls[\"current\"] = dpw_pls[\"o_cli_id\"].isin(dpw_pls.loc[dpw_pls.pl_end_dt.isnull(), \"o_cli_id\"]).map({True: \"Current\", False: \"Ended\"})\nta5 = (\n    dpw_pls.groupby(['o_cli_id', 'known_apw', 'current']).route_id.nunique().rename(\"routes\")\n    .reset_index(level=[\"known_apw\", \"current\"]).value_counts()\n    .unstack([0, 1], fill_value=0).swaplevel(axis=1).sort_index()\n    .assign(All=lambda x: x.sum(axis=\"columns\"))\n)\nta5.index = ta5.index.astype(\"object\")\n# ta5.columns = pd.Categorical(ta5.columns, categories=[\"Returned\", \"New\", \"All\"], ordered=True)\n# ta5 = ta5.rename_axis(\"Records pre-DPW\", axis=\"columns\")\n# ta5 = ta5.sort_index(axis=\"columns\")\nta5.loc[\"n\", :] = ta5.sum()\nta5_pct_col = ta5.apply(lambda x: (x/x.loc[\"n\"]).mul(100))\ngrp_sum = ta5.T.groupby(\"current\").transform(\"sum\").T\ngrp_sum.iloc[:-1] = grp_sum.iloc[-1].values\nta5_pct_grp = 100 * ta5 / grp_sum\nta5_pct_all = ta5[[\"Ended\", \"Current\"]].apply(lambda x: (x/ta5[\"All\"].loc[\"n\"]).mul(100))\nta5_numeric = (\n    pd.concat([ta5_pct_col, ta5_pct_grp, ta5_pct_all, ta5], keys=[\"% col\", \"% grp\", \"% All\", \"n\"], axis=\"columns\")\n    .swaplevel(0, 2, axis=\"columns\").swaplevel(0, 1, axis=\"columns\")\n    .sort_index(axis=\"columns\", level=[0, 1], sort_remaining=False)\n    [[\"Ended\", \"Current\", \"All\"]]\n).copy()\nformats = {(a, b, c): \"{0:.1f}%\" if c[0] == \"%\" else \"{0:,.0f}\" for a, b, c in ta5_numeric.columns}\nta5 = ta5_numeric.apply(lambda x: x.apply(formats[x.name].format))\nexcel_output[\"Table A.5: Routes per person during studied period by current/ended and whether placed in BAHSA before studied period\"] = ta5\n\n# Generate Figure 4.6\nimport numpy as np\nimport seaborn as sns\nimport seaborn.objects as so\nimport matplotlib.pyplot as plt\nsns.set()\ncol_x = \"n\"\nplotdata = ta5_numeric.swaplevel(0, 2, axis=1).loc[:8, col_x][[\"New\", \"Returned\"]].stack([0, 1]).rename(col_x).reset_index()\nplotdata[\"known_apw\"] = plotdata[\"known_apw\"].astype(\"string\")\nmaxes = ta5_numeric.swaplevel(0, 2, axis=1)[\"n\"].loc[\"n\"].groupby(level=0).sum()\nwidth_ratios = maxes[[\"New\", \"Returned\"]]\nwidth_ratios = width_ratios - (width_ratios.sum()/52.7)\ncolours = sns.color_palette(as_cmap=False)\nfig_overall = plt.figure(layout=\"constrained\", figsize=(6.2, 3.1))\nfig_l, fig_r = fig_overall.subfigures(1, 2, width_ratios=width_ratios)\nfor grp, fig, col in [(\"Returned\", fig_r, colours[1]),\n                      (\"New\",      fig_l, colours[0])]:\n    pl_d = plotdata[plotdata[\"known_apw\"] == grp].reset_index(drop=True)\n    pl_d[\"routes\"] = pl_d[\"routes\"].astype(\"category\")\n    textdata_after = (pl_d.groupby(\"routes\", observed=False)[col_x].sum().to_frame()\n                      .assign(text=lambda x: (x/x.sum()).mul(100).map(lambda y: f\"{y:,.1f}%\")))\n    textdata_after.iloc[-1, -1] += f\" (of {grp})\"\n    textdata_during = (pl_d.assign(pct_all=pl_d.groupby(\"routes\", observed=False)[col_x]\n                                   .transform(lambda x: (x/pl_d[col_x].sum()).mul(100))))\n    textdata_during = textdata_during[textdata_during[\"pct_all\"] &gt; 15]\n    textdata_during.loc[textdata_during[\"current\"] == \"Ended\", \"x\"] = (\n        textdata_during.loc[textdata_during[\"current\"] == \"Ended\", col_x] / 2)\n    textdata_during.loc[textdata_during[\"current\"] == \"Current\", \"x\"] = (\n        textdata_during.loc[textdata_during[\"current\"] == \"Current\"].join(\n            textdata_during.loc[textdata_during[\"current\"] == \"Ended\"].set_index(\"routes\")[col_x],\n            on=\"routes\", rsuffix=\"_end\")\n        .apply(lambda x: x[col_x+\"_end\"] + x[col_x]/2, axis=1))\n\n    textdata_during[\"text\"] = textdata_during[\"pct_all\"].map(lambda y: f\"{y:,.1f}%\")\n    if grp == \"New\":\n        textdata_during.iloc[0, -1] += f\" of {grp} ({100*textdata_during.iloc[0][col_x]/plotdata[col_x].sum():.1f}% of all)\"\n    p = (\n        so.Plot(data=pl_d, y=\"routes\", x=col_x)\n        .add(so.Bars(), so.Stack(), color=\"current\", legend=False)\n        .add(so.Text(color=\".4\", fontsize=11, halign=\"left\", offset=2, alpha=0.7), data=textdata_after, x=col_x, y=\"routes\", text=\"text\")\n        .label(x=\"People\", title=f\"{grp}\" + \" (${n}$=\" + f\"{int(maxes[grp]):,})\", y=\"\")\n        .limit(x=(0, maxes[grp]))\n        .layout(engine=\"constrained\")\n        .on(fig)\n        .plot()\n    )\n    ax = fig.axes[0]\n    if grp == \"New\":\n        colours = sns.color_palette(as_cmap=False)\n        T = matplotlib.patches.Patch(facecolor=colours[0], edgecolor=\"white\", alpha=0.8, label=\"Ended\")\n        F = matplotlib.patches.Patch(facecolor=colours[1], edgecolor=\"white\", alpha=0.8, label=\"Current\")\n        ax.legend(handles=[F, T], loc=\"lower right\")\n    minor_ticks = [((b-a)/2 + a) for a, b in zip(ax.get_yticks()[:-1], ax.get_yticks()[1:])]\n    # labels = ta5.swaplevel(axis=1)[\"% col\"][grp].iloc[:-1].map(lambda x: x[:-1])\n    ax.set_xticks([maxes[grp]], labels=[\"${n}$\"])\n    ax.set_xticks(range(0, int(maxes[grp]), 500), labels=list(range(0, int(maxes[grp]), 500))[:-1] + [\"..\"], minor=True)\n    ax.tick_params(\"x\", which=\"minor\", pad=3, bottom=True, width=0.5, length=5)\n    ax.tick_params(\"x\", which=\"major\", pad=3, bottom=True, width=0.5, length=5)\n    ax.set_yticks(ax.get_yticks(), labels=[])\n    ax.set_yticks(minor_ticks, minor=True)\n    ax.grid(which=\"minor\", axis=\"y\")\n    ax.grid(which=\"minor\", axis=\"x\")\nyticks = fig_l.axes[0].get_yticks()\nsec = fig_l.axes[0].secondary_yaxis(location=0)\nsec.set_yticks(yticks, labels=[y + 1 for y in yticks])\nsec.tick_params(\"y\", length=0, which=\"both\", pad=8)\nsec.set_ylabel(\"Routes\", labelpad=6)\nfig_4_6 = \"img_output/Figure_4.6.svg\"\nplt.savefig(fig_4_6)\npass\n\n\n\n\nFigure 4.6\n\nNotes: X-axis scales are proportionate to New/Returned counts. ‘New’ means no record of using services since April 2009. Full data table is Table A.5.\n\n\nTable A.5\n\n\n\n\n\n\n\n\ncurrent\nEnded\nCurrent\nAll\n\n\nknown_apw\nNew\nReturned\nNew\nReturned\n\n\n\n\n% col\n% grp\n% All\nn\n% col\n% grp\n% All\nn\n% col\n% grp\n% All\nn\n% col\n% grp\n% All\nn\n% col\n% grp\nn\n\n\nroutes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n83.4%\n56.0%\n45.0%\n1,690\n70.0%\n23.0%\n18.5%\n694\n79.3%\n63.3%\n12.4%\n467\n51.7%\n10.4%\n2.1%\n77\n78.0%\n78.0%\n2,928\n\n\n2\n12.4%\n8.3%\n6.7%\n251\n16.5%\n5.4%\n4.4%\n164\n13.8%\n11.0%\n2.2%\n81\n24.2%\n4.9%\n1.0%\n36\n14.2%\n14.2%\n532\n\n\n3\n3.0%\n2.0%\n1.6%\n60\n7.9%\n2.6%\n2.1%\n78\n3.1%\n2.4%\n0.5%\n18\n13.4%\n2.7%\n0.5%\n20\n4.7%\n4.7%\n176\n\n\n4\n0.8%\n0.6%\n0.5%\n17\n2.9%\n1.0%\n0.8%\n29\n2.4%\n1.9%\n0.4%\n14\n6.7%\n1.4%\n0.3%\n10\n1.9%\n1.9%\n70\n\n\n5\n0.3%\n0.2%\n0.2%\n6\n1.4%\n0.5%\n0.4%\n14\n1.0%\n0.8%\n0.2%\n6\n2.0%\n0.4%\n0.1%\n3\n0.8%\n0.8%\n29\n\n\n6\n0.1%\n0.1%\n0.1%\n2\n0.7%\n0.2%\n0.2%\n7\n0.5%\n0.4%\n0.1%\n3\n1.3%\n0.3%\n0.1%\n2\n0.4%\n0.4%\n14\n\n\n7\n0.0%\n0.0%\n0.0%\n0\n0.4%\n0.1%\n0.1%\n4\n0.0%\n0.0%\n0.0%\n0\n0.7%\n0.1%\n0.0%\n1\n0.1%\n0.1%\n5\n\n\n8\n0.0%\n0.0%\n0.0%\n0\n0.1%\n0.0%\n0.0%\n1\n0.0%\n0.0%\n0.0%\n0\n0.0%\n0.0%\n0.0%\n0\n0.0%\n0.0%\n1\n\n\nn\n100.0%\n67.2%\n54.0%\n2,026\n100.0%\n32.8%\n26.4%\n991\n100.0%\n79.8%\n15.7%\n589\n100.0%\n20.2%\n4.0%\n149\n100.0%\n100.0%\n3,755"
  },
  {
    "objectID": "4.3_number_of_routes.html#tables-in-an-excel-file",
    "href": "4.3_number_of_routes.html#tables-in-an-excel-file",
    "title": "4.3 Results - Number of routes",
    "section": "Tables in an Excel file",
    "text": "Tables in an Excel file\n\nCode\nimport os\nsheetname = \"Sheet1\"\nqmdfile = os.getenv(\"QUARTO_DOCUMENT_FILE\")\nfilename = \"img_output/\"+qmdfile[:-4]+\".xlsx\"\nwith pd.ExcelWriter(filename) as writer:\n    next_row = 0\n    for k, v in excel_output.items():\n        pd.DataFrame([k]).to_excel(writer, sheet_name=sheetname, header=False, index=False, startrow=next_row)\n        next_row += 1\n        v.to_excel(writer, sheet_name=sheetname, startrow=next_row, float_format=\"%.1f\")\n        next_row += (\n            (1 if not isinstance(v.columns, pd.MultiIndex) else 1 + len(v.columns.levels))\n            + len(v) + 1)\nprint(f\"[Excel file](./{filename})\")\n\nExcel file"
  },
  {
    "objectID": "4.1_outcomes.html",
    "href": "4.1_outcomes.html",
    "title": "4.1 Results - Outcomes",
    "section": "",
    "text": "Code\n# Setup code\nimport pandas as pd\nfrom python_scripts import setup\nfrom python_scripts import services\nfrom python_scripts import helper\ndf, dffp = setup.setup(verbose=False)\n\nfrom python_scripts import distinct_pathways\ndpw_pls = distinct_pathways.get_distinct_pathways_routes(dffp)\nqrows = dpw_pls[\"rt_end_cat\"] == \"[Not ended or invalid end reason]\"\ndpw_pls.loc[qrows, \"rt_end_cat\"] = dpw_pls.loc[qrows, \"pl_end_dt\"].isna().map({True: \"[Not ended]\", False: \"Missing data/error\"})\ndpw_pls[\"rt_end_cat\"] = dpw_pls[\"rt_end_cat\"].str.replace(\"To care/hosp.\", \"To care/hospital\")\ndpw_rt_starts = dpw_pls.groupby(\"route_id\").head(1)\ndpw_rt_ends = dpw_pls.groupby(\"route_id\").tail(1)\ndpw_clis = dpw_pls.groupby([\"o_cli_id\"]).head(1)  # 1 duplicate client but first entry has more detailed answers\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams.update({\n    'figure.figsize': (6.2, 4.1),\n    'font.size': 12,\n    'figure.constrained_layout.use': True\n})\n\nexcel_output = {}"
  },
  {
    "objectID": "4.1_outcomes.html#outcomes-rq1",
    "href": "4.1_outcomes.html#outcomes-rq1",
    "title": "4.1 Results - Outcomes",
    "section": "Outcomes (RQ1)",
    "text": "Outcomes (RQ1)\n\nFigure 4.1: Route end reason proportions\n\nCode\n\n\nCode\n# Generate Table A.3\nta3_data = dpw_rt_ends.copy()\nta3 = ta3_data[\"rt_end_cat\"].value_counts(dropna=False).rename(\"all_routes\").to_frame()\nta3 = ta3.assign(latest_route=ta3_data.groupby(\"o_cli_id\").tail(1)[\"rt_end_cat\"].value_counts(dropna=False))\nta3_end_rows = [\"Missing data/error\", \"[Not ended]\"]\nta3 = ta3.reindex([x for x in ta3.index if x not in ta3_end_rows] + ta3_end_rows)\nprop_include = ta3.index.difference([\"Missing data/error\", \"[Not ended]\"])\nta3_prop = ta3.loc[prop_include].apply(lambda x: x/x.sum()).mul(100)\nta3 = pd.concat([ta3, ta3_prop], keys=[\"n\", \"%\"], axis=\"columns\").swaplevel(axis=\"columns\")\nlvl1 = [\"all_routes\", \"latest_route\"]\nta3 = ta3.reindex(((a, b) for a in lvl1 for b in [\"n\", \"%\"]), axis=\"columns\")\nta3_numeric = ta3.copy()\nta3_total = ta3.sum()\nta3_total.loc[slice(None), \"%\"] = pd.NA\nta3.loc[\"Valid ended (n)\"] = ta3.loc[prop_include].sum()\nta3.loc[\"Total (n)\"] = ta3_total\nta3.loc[:, (lvl1, \"n\")] = ta3.loc[:, (lvl1, \"n\")].map(lambda x: f\"{x:,.0f}\" if not pd.isna(x) else pd.NA)\nta3.loc[:, (lvl1, \"%\")] = ta3.loc[:, (lvl1, \"%\")].map(lambda x: f\"{x:.1f}%\" if not pd.isna(x) else pd.NA)\nend_props_order = ta3.index\nexcel_output[\"Table A.3: Route end reasons\"] = ta3\n\n# Generate Figure 4.1\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nrelevant_numeric = ta3_numeric\nmissing = [\"Missing data/error\", \"[Not ended]\"]\ntotal_n = relevant_numeric.swaplevel(axis=\"columns\")[\"n\"].sum()\ntotal_na = relevant_numeric.swaplevel(axis=\"columns\").loc[missing][\"n\"].sum()\nvalid_n = total_n - total_na\nplotdata = (\n    relevant_numeric.drop(index=missing)\n    .swaplevel(axis=\"columns\")[\"%\"].unstack().rename(\"%\").to_frame().reset_index()\n    .rename(columns={\"level_0\": \"routes\"})\n    .replace({\"all_routes\": f\"Per route (all ended routes)\\n$n$={valid_n[\"all_routes\"]:,}\",\n              \"latest_route\": f\"Per person (latest route)\\n$n$={valid_n[\"latest_route\"]:,}\"})\n)\nplotlabels = pd.DataFrame({\"x\": -10, \"y\": plotdata[\"rt_end_cat\"], \"text\": plotdata[\"%\"].map(lambda x: f\"{x:.1f}%\")})\ncolors = sns.color_palette()\ncolors = colors[4:6]\np = (\n    so.Plot(data=plotdata, y=\"rt_end_cat\", x=\"%\", color=\"routes\")\n    .theme({\"ytick.major.pad\": 35, \"font.size\": 12, \"axes.titlesize\": \"medium\"})\n    .add(so.Bar(edgewidth=0), legend=False)\n    .add(so.Text({\"clip_on\": False}, halign=\"left\"), data=plotlabels, x=\"x\", y=\"y\", text=\"text\", legend=False)\n    .label(y=None, x=None)\n    .scale(x=so.Continuous().label(like=\"{x:.0f}%\"), color=colors)\n    .limit(x=(0, None))\n    .facet(col=\"routes\")\n    .layout(size=(7.2, 3.7), engine=\"constrained\")\n)\nfig_4_1 = \"img_output/Figure_4.1.svg\"\np.save(fig_4_1)\npass\n\n\n\n\nFigure 4.1\n\nNotes: Full data table is Table A.3. “Latest” is the most recent route for each person.\n\n\nTable A.3\n\n\n\n\n\n\n\n\n\nall_routes\nlatest_route\n\n\n\nn\n%\nn\n%\n\n\nrt_end_cat\n\n\n\n\n\n\n\n\nTo social housing\n999\n23.6%\n978\n33.2%\n\n\nEvicted\n867\n20.5%\n415\n14.1%\n\n\nAbandoned\n639\n15.1%\n339\n11.5%\n\n\nTo friends/family\n376\n8.9%\n281\n9.5%\n\n\nCustody\n336\n7.9%\n148\n5.0%\n\n\nOther\n289\n6.8%\n204\n6.9%\n\n\nTo private rented\n278\n6.6%\n249\n8.5%\n\n\nTo care/hospital\n171\n4.0%\n102\n3.5%\n\n\nTo external supported\n167\n3.9%\n113\n3.8%\n\n\nDied\n117\n2.8%\n117\n4.0%\n\n\nMissing data/error\n95\n&lt;NA&gt;\n71\n&lt;NA&gt;\n\n\n[Not ended]\n738\n&lt;NA&gt;\n738\n&lt;NA&gt;\n\n\nValid ended (n)\n4,239\n100.0%\n2,946\n100.0%\n\n\nTotal (n)\n5,072\n&lt;NA&gt;\n3,755\n&lt;NA&gt;\n\n\n\n\n\n\n\n\n\n\nFigure 4.2: End reason proportions for new people’s first routes\n\nCode\n\n\nCode\n# Generate Table A.4\npl_before_dpw_start = dffp.loc[(dffp[\"pl_start_dt\"] &lt; distinct_pathways.dpw_start_dt), \"o_cli_id\"].unique()\ndpw_clis_before_start = dpw_clis.loc[dpw_clis[\"o_cli_id\"].isin(pl_before_dpw_start), \"o_cli_id\"]\nta4_data = dpw_rt_ends[~dpw_rt_ends[\"o_cli_id\"].isin(dpw_clis_before_start)].groupby(\"o_cli_id\").head(1).copy()\nta4 = ta4_data[\"rt_end_cat\"].value_counts(dropna=False).rename(\"all_routes\").to_frame()\nta4_end_rows = [\"Missing data/error\", \"[Not ended]\"]\nta4 = ta4.reindex([x for x in ta4.index if x not in ta4_end_rows] + ta4_end_rows)\nprop_include = ta4.index.difference([\"Missing data/error\"])\nta4_prop = ta4.loc[prop_include].apply(lambda x: x/x.sum()).mul(100)\nprop_notended_include = ta4_prop.index.difference([\"[Not ended]\"])\nta4_prop_notended = ta4.loc[prop_notended_include].apply(lambda x: x/x.sum()).mul(100)\nta4 = pd.concat([ta4, ta4_prop_notended], keys=[\"n\", \"% of ended\"], axis=\"columns\").swaplevel(axis=\"columns\")\nta4 = ta4.droplevel(0, axis=1)\nta4_numeric = ta4.copy()\nta4_numeric = ta4_numeric.reindex(end_props_order).dropna(how=\"all\")\nta4_total = ta4.sum()\nta4_total.loc[\"% of ended\"] = pd.NA\nta4.loc[\"Valid ended (n)\"] = ta4.loc[prop_notended_include].sum()\nta4.loc[\"Total (n)\"] = ta4_total\nta4.loc[:, \"n\"] = ta4.loc[:, \"n\"].map(lambda x: f\"{x:,.0f}\" if not pd.isna(x) else pd.NA)\n# ta4.loc[:, \"% of all\"] = ta4.loc[:, \"% of all\"].map(lambda x: f\"{x:.1f}%\" if not pd.isna(x) else pd.NA)\nta4.loc[:, \"% of ended\"] = ta4.loc[:, \"% of ended\"].map(lambda x: f\"{x:.1f}%\" if not pd.isna(x) else pd.NA)\nta4 = ta4.reindex(end_props_order).dropna(how=\"all\")\nexcel_output[\"Table A.4: Route end reasons: first routes for people with no records of previously using BAHSA services\"] = ta4\n\n# Generate Figure 4.2\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn.objects as so\nrelevant_numeric = ta4_numeric\nmissing = [\"Missing data/error\", \"[Not ended]\"]\ntotal_n = relevant_numeric[\"n\"].sum()\ntotal_na = relevant_numeric.loc[missing][\"n\"].sum()\nvalid_n = (total_n - total_na).astype(\"int64\")\nplotdata = (\n    relevant_numeric.drop(index=missing)[\"% of ended\"].rename(\"%\").to_frame().reset_index()\n)\nplotlabels = pd.DataFrame({\"x\": -9, \"y\": plotdata[\"rt_end_cat\"], \"text\": plotdata[\"%\"].map(lambda x: f\"{x:.1f}%\")})\ncolors = sns.color_palette()\ncolors = colors[6:7]\np = (\n    so.Plot(data=plotdata, y=\"rt_end_cat\", x=\"%\", color=1)\n    .theme({\"ytick.major.pad\": 35, \"font.size\": 12, \"axes.titlesize\": \"medium\"})\n    .add(so.Bar(edgewidth=0), legend=False)\n    .add(so.Text({\"clip_on\": False}, halign=\"left\", fontsize=11), data=plotlabels, x=\"x\", y=\"y\", text=\"text\", legend=False)\n    .label(y=None, x=None, title=f\"Per person (first route)\\n$n$={valid_n:,}\")\n    .scale(x=so.Continuous().label(like=\"{x:.0f}%\"), color=colors)\n    .limit(x=(0, 35))\n    .layout(size=(4.2, 3.7), engine=\"constrained\")\n)\nfig_4_2 = \"img_output/Figure_4.2.svg\"\np.save(fig_4_2)\npass\n\n\n\n\nFigure 4.2\n\nNotes: Full data table is Table A.4. People with no records of previously using BAHSA services.\n\n\nTable A.4\n\n\n\n\n\n\n\n\n\nn\n% of ended\n\n\nrt_end_cat\n\n\n\n\n\n\nTo social housing\n469\n26.0%\n\n\nEvicted\n327\n18.1%\n\n\nAbandoned\n230\n12.7%\n\n\nTo friends/family\n195\n10.8%\n\n\nCustody\n98\n5.4%\n\n\nOther\n154\n8.5%\n\n\nTo private rented\n166\n9.2%\n\n\nTo care/hospital\n61\n3.4%\n\n\nTo external supported\n69\n3.8%\n\n\nDied\n38\n2.1%\n\n\nMissing data/error\n57\n&lt;NA&gt;\n\n\n[Not ended]\n451\n&lt;NA&gt;\n\n\nValid ended (n)\n1,807\n100.0%\n\n\nTotal (n)\n2,315\n&lt;NA&gt;"
  },
  {
    "objectID": "4.1_outcomes.html#tables-in-an-excel-file",
    "href": "4.1_outcomes.html#tables-in-an-excel-file",
    "title": "4.1 Results - Outcomes",
    "section": "Tables in an Excel file",
    "text": "Tables in an Excel file\n\nCode\nimport os\nsheetname = \"Sheet1\"\nqmdfile = os.getenv(\"QUARTO_DOCUMENT_FILE\")\nfilename = \"img_output/\"+qmdfile[:-4]+\".xlsx\"\nwith pd.ExcelWriter(filename) as writer:\n    next_row = 0\n    for k, v in excel_output.items():\n        pd.DataFrame([k]).to_excel(writer, sheet_name=sheetname, header=False, index=False, startrow=next_row)\n        next_row += 1\n        v.to_excel(writer, sheet_name=sheetname, startrow=next_row, float_format=\"%.1f\")\n        next_row += (\n            (1 if not isinstance(v.columns, pd.MultiIndex) else 1 + len(v.columns.levels))\n            + len(v) + 1)\nprint(f\"[Excel file](./{filename})\")\n\nExcel file"
  },
  {
    "objectID": "4.2_capacity_and_throughput.html",
    "href": "4.2_capacity_and_throughput.html",
    "title": "4.2 Results - Capacity and throughput",
    "section": "",
    "text": "Code\n%config InlineBackend.figure_formats = ['svg']\n# Setup code\nimport pandas as pd\nfrom python_scripts import setup\nfrom python_scripts import services\nfrom python_scripts import helper\ndf, dffp = setup.setup(verbose=False)\n\nfrom python_scripts import distinct_pathways\ndpw_pls = distinct_pathways.get_distinct_pathways_routes(dffp)\nqrows = dpw_pls[\"rt_end_cat\"] == \"[Not ended or invalid end reason]\"\ndpw_pls.loc[qrows, \"rt_end_cat\"] = dpw_pls.loc[qrows, \"pl_end_dt\"].isna().map({True: \"[Not ended]\", False: \"Missing data/error\"})\ndpw_pls[\"rt_end_cat\"] = dpw_pls[\"rt_end_cat\"].str.replace(\"To care/hosp.\", \"To care/hospital\")\ndpw_rt_starts = dpw_pls.groupby(\"route_id\").head(1)\ndpw_rt_ends = dpw_pls.groupby(\"route_id\").tail(1)\ndpw_clis = dpw_pls.groupby([\"o_cli_id\"]).head(1)  # 1 duplicate client but first entry has more detailed answers\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams.update({\n    'figure.figsize': (6.2, 4.1),\n    'font.size': 12,\n    'figure.constrained_layout.use': True\n})\n\nexcel_output = {}"
  },
  {
    "objectID": "4.2_capacity_and_throughput.html#capacity-and-throughput-rq2",
    "href": "4.2_capacity_and_throughput.html#capacity-and-throughput-rq2",
    "title": "4.2 Results - Capacity and throughput",
    "section": "Capacity and throughput (RQ2)",
    "text": "Capacity and throughput (RQ2)\n\nFigure 4.3: Allocated placements per night\n\nCode\n\n\nCode\nfirst_date = pd.Timestamp('2017-10-28')\nlast_date = pd.Timestamp('2025-04-30')\ndate_range = pd.date_range(first_date, last_date, freq=\"d\")\n\nvoidsdf = df.all[\n    (~df.all.cli_id.isin(dffp.cli_id)) &\n    df.all.svc_type.isin(services.distinct_pathways_accom_svc_types + [\"Accommodation Based - Supported Move-on\"])\n]\ntempdf = dffp\ntempdf = pd.concat([\n    tempdf.loc[\n        tempdf.svc_type.isin(services.distinct_pathways_accom_svc_types + [\"Accommodation Based - Supported Move-on\"]),\n        [\"vac_start_dt\", \"pl_start_dt\", \"pl_end_dt\", \"vac_end_dt\", \"svc_type\"]\n    ],\n    voidsdf.assign(pl_start_dt=pd.NA, pl_end_dt = pd.NA)[[\"vac_start_dt\", \"pl_start_dt\", \"pl_end_dt\", \"vac_end_dt\", \"svc_type\"]]\n])\ntempdf.vac_end_dt = tempdf.vac_end_dt.fillna(last_date + pd.Timedelta(days=1))\ntempdf.pl_end_dt = tempdf.pl_end_dt.fillna(tempdf.vac_end_dt)\nnightly_vac = []\nfor day in date_range:\n    dpw_voids = (\n        tempdf.svc_type.isin(services.distinct_pathways_accom_svc_types) &\n        (tempdf.vac_start_dt &lt;= day) & (tempdf.vac_end_dt &gt; day) &\n        (\n            tempdf.pl_start_dt.isnull() |\n            (tempdf.pl_start_dt &gt; day) |\n            (tempdf.pl_end_dt &lt;= day)\n        )\n    ).sum()\n    dpw_stays = (\n        tempdf.svc_type.isin(services.distinct_pathways_accom_svc_types) &\n        (tempdf.pl_start_dt &lt;= day) & (tempdf.pl_end_dt &gt; day)\n    ).sum()\n    non_dpw_voids = (\n        (~tempdf.svc_type.isin(services.distinct_pathways_accom_svc_types)) &\n        (tempdf.vac_start_dt &lt;= day) & (tempdf.vac_end_dt &gt; day) &\n        (\n            tempdf.pl_start_dt.isnull() |\n            (tempdf.pl_start_dt &gt; day) |\n            (tempdf.pl_end_dt &lt;= day)\n        )\n    ).sum()\n    non_dpw_stays = (\n        (~tempdf.svc_type.isin(services.distinct_pathways_accom_svc_types)) &\n        (tempdf.pl_start_dt &lt;= day) & (tempdf.pl_end_dt &gt; day)\n    ).sum()\n    nightly_vac.append({\n        \"day\": day,\n        \"dpw_stays\": dpw_stays,\n        \"dpw_voids\": dpw_voids,\n        \"non_dpw_stays\": non_dpw_stays,\n        \"non_dpw_voids\": non_dpw_voids\n    })\nnightly_vac_df = pd.DataFrame.from_dict(nightly_vac)\n\n# Nightly\nnightly_ave = nightly_vac_df.copy().set_index(\"day\")\nnightly_ave = (\n    nightly_ave.groupby(nightly_ave.index.to_period(\"d\").start_time)\n    .mean().reset_index()\n)\n\n# Prepare graph\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n# ymax = 1060\nymax = 920\nratio = 5\nedgecolor = \"white\"\nalpha = 0.8\naxs = [None]\n# fig, axs = plt.subplots(2, 1, sharey=False, sharex=False, height_ratios=[ratio, 1], figsize=(12, 8))\nplt.rcParams.update({'font.size': 12, 'figure.figsize': (7.1, 4.8), 'figure.constrained_layout.use': True})\nfig, axs[0] = plt.subplots()\nplt.subplots_adjust(bottom=0.13, left=0.13, right=0.95, top=0.95)\naxs[0].stackplot(\n    nightly_ave.day,\n    [nightly_ave.dpw_stays], #, nightly_ave.non_dpw_stays],\n    colors=[\"C2\", \"C4\"],\n    alpha=alpha,\n    lw=0,\n)\naxs[0].set_ylim(0, ymax)\naxs[0].yaxis.set_label_text(\"Allocated placements\")\naxs[0].xaxis.set_label_text(\"Date\")\naxs[0].legend(loc=\"lower right\", reverse=True)\n\nfor ax in axs:\n    ax.set_xlim(first_date, last_date)\n    ax.yaxis.set_minor_locator(locator=matplotlib.ticker.MultipleLocator(100))\n    ax.yaxis.grid(True, which=\"minor\")\n    ax.xaxis.set_major_locator(locator=matplotlib.dates.YearLocator(base=1))\n    ax.xaxis.set_minor_locator(locator=matplotlib.dates.MonthLocator(bymonth=7))\n    ax.xaxis.grid(True, which=\"minor\")\n    ax.tick_params(bottom=True, left=True, color=\"lightgrey\", labelcolor=\"grey\")\n\nfig_4_3 = \"img_output/Figure_4.3.svg\"\nplt.savefig(fig_4_3)\npass\n\n\n\n\nFigure 4.3\n\nNotes: Date range 28/10/2017–30/04/2025\n\n\n\nFigure 4.4: Exits from BAHSA by calendar year\n\nCode\n\n\nCode\n# Prepare data\ndf_route_ends = dpw_pls.groupby('route_id').tail(1)\nct_df = df_route_ends.copy().assign(end_yr=df_route_ends.pl_end_dt.dt.year)\nct_df.end_yr = ct_df.end_yr.astype(\"Int64\")\nct_df.loc[\n    ct_df.rt_end_cat.isin([\"[Not ended or invalid end reason]\", \"Missing data/error\"]),\n    \"rt_end_cat\"\n] = \"Missing data/errors\"\nct_df[\"Pathway\"] = ct_df.svc_type_short.rename(\n    {\"Male Only Pathway\": \"M\", \"Female Only Pathway\": \"F\",\n    \"Mixed Pathway\": \"M/F\", \"Substance Misuse Pathway\": \"SU\"})\n\n# Plot the chart\nimport seaborn.objects as so\nplotdata = (\n    ct_df.groupby(\"end_yr\").size().drop([2017,2025]).to_frame(name=\"exits\")\n    .reset_index()\n    .rename(columns={\"end_yr\": \"x\", \"exits\": \"y\"})\n)\nlimits = (plotdata[\"y\"].min(), plotdata[\"y\"].max())\np = (\n    so.Plot(plotdata, x=\"x\", y=\"y\")\n    .label(x=\"Year\", y=\"Exits\")\n    .limit(y=(0, 725), x=(2018, 2024))\n)\nlimpos = 2022.5\nfor lim in limits:\n    p = p.add(so.Line(linestyle=(3,6), color=\".6\", linewidth=0.8), data=pd.DataFrame({\"x\": [2018, 2024], \"y\": [lim] * 2}))\np = (\n    p.add(so.Line(linewidth=3))\n    .add(so.Dot())\n    .add(so.Area())\n    .add(\n        so.Text({\"clip_on\": False}, halign=\"right\", valign=\"center\", fontsize=9, color=\".6\", offset=1),\n        data=pd.DataFrame({\"x\": [2018] * 2, \"y\": list(limits), \"text\": [str(x) for x in limits]}),\n        x=\"x\", y=\"y\", text=\"text\"\n    )\n)\nfig_4_4 = \"img_output/Figure_4.4.svg\"\np.save(fig_4_4)\npass\n\n\n\n\nFigure 4.4\n\nNotes: Full data table is Table A.2. People can have more than one exit in a year. Moves within or between services and incomplete years (2017 and 2025) are excluded.\n\n\n\nFigure 4.5: Exits from BAHSA by calendar year and end reason\n\nCode\n\n\nCode\nct = (\n    pd.crosstab(\n        ct_df.end_yr.rename(\"Year\"),\n        [ct_df.rt_end_cat.rename(\"End reason\"), ct_df[\"Pathway\"]],\n        normalize=False,\n        margins=True\n    ).drop(index=[2017, 2025])  # Drop incomplete/unusual years\n    .sort_values(by=\"All\", axis=1, ascending=False)\n    .drop(index=\"All\", columns=\"All\")\n    .unstack()\n    .rename(\"exits\")\n    .reset_index()\n)\nct_all = ct.drop(columns=\"Pathway\").groupby([\"End reason\", \"Year\"], sort=False).sum().reset_index().assign(Pathway=\"All\")\nn_ends = ct[\"End reason\"].nunique()\norder = [\"Social housing\", \"Private rented\", \"Friends/family\", \"Supported¹\",\n         \"Evicted\", \"Abandoned\", \"Custody\", \"Care/hospital\",\n         \"Other\", \"Died\", \"Missing data/errors\"]\np = (\n    so.Plot(data=ct_all, x=\"Year\", y=\"exits\")\n    .theme({\"axes.grid.which\": \"both\"})\n    .label(x=\"\", y=\"\")\n    .layout(size=(7, 4.1))\n    .limit(y=(0, 200), x=(2018, 2024))\n    .add(so.Dot(pointsize=3), legend=False)\n    .add(so.Line(), legend=False)\n    .add(so.Line(color=\".6\", linestyle=(4, 2)), so.PolyFit(1), legend=False)\n    .scale(x=so.Continuous().tick(every=9, minor=8))\n    .facet(\"End reason\", wrap=4, order=order)\n)\nfig_4_5 = \"img_output/Figure_4.5.svg\"\np.save(fig_4_5)\npass\n\n\n\n\nFigure 4.5\n\nNotes: Period covered is 2018-2024, vertical gridlines represent years 2019-2023, as in Figure 4.4. Full data table is Table A.2. 1. ‘Supported’ is moves to support services outside BAHSA.\n\n\nTable A.2\n\n\nCode\nta2 = (\n    pd.crosstab(\n        ct_df.rt_end_cat.rename(\"Exit reason\"), \n        ct_df.end_yr.rename(\"Year\"),\n        normalize=False,\n        margins=True\n    )\n    .sort_values(by=\"All\", axis=0, ascending=False)\n    .pipe(lambda df: df.reindex(list(df.index.drop(\"All\")) + [\"All\"]))  # Move total back to bottom\n)\nyears = ta2.columns.values[:-1]\ndays = ([(pd.Timestamp(f\"{years[0]+1}-01-01\") - distinct_pathways.dpw_start_dt).days] +\n        [(pd.Timestamp(f\"{y+1}-01-01\") - pd.Timestamp(f\"{y}-01-01\")).days for y in years[1:-1]] +\n        [(distinct_pathways.dpw_end_dt - pd.Timestamp(f\"{years[-1]}-01-01\")).days])\nta2.columns = pd.MultiIndex.from_arrays([ta2.columns.values, days + [sum(days)]], names=(\"Year\", \"Days\"))\nexcel_output[\"Table A.2: Exits from BAHSA per calendar year by end reasons\"] = ta2\ndisplay(ta2)\n\n\n\n\n\n\n\n\nYear\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025\nAll\n\n\nDays\n65\n365\n365\n366\n365\n365\n365\n366\n119\n2741\n\n\nExit reason\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo social housing\n35\n177\n154\n178\n134\n125\n79\n88\n29\n999\n\n\nEvicted\n21\n101\n127\n101\n112\n121\n133\n109\n42\n867\n\n\nAbandoned\n18\n87\n100\n83\n83\n76\n98\n79\n15\n639\n\n\nTo friends/family\n14\n74\n73\n49\n47\n53\n35\n15\n16\n376\n\n\nCustody\n5\n51\n44\n61\n57\n40\n41\n26\n11\n336\n\n\nOther\n8\n42\n30\n38\n44\n40\n27\n44\n16\n289\n\n\nTo private rented\n7\n30\n42\n64\n39\n35\n19\n33\n9\n278\n\n\nTo care/hospital\n4\n26\n31\n20\n26\n13\n19\n24\n8\n171\n\n\nTo external supported\n5\n40\n16\n20\n25\n19\n16\n18\n8\n167\n\n\nDied\n2\n17\n17\n16\n20\n13\n14\n15\n3\n117\n\n\nMissing data/errors\n2\n23\n15\n5\n8\n5\n12\n4\n21\n95\n\n\nAll\n121\n668\n649\n635\n595\n540\n493\n455\n178\n4334"
  },
  {
    "objectID": "4.2_capacity_and_throughput.html#tables-in-an-excel-file",
    "href": "4.2_capacity_and_throughput.html#tables-in-an-excel-file",
    "title": "4.2 Results - Capacity and throughput",
    "section": "Tables in an Excel file",
    "text": "Tables in an Excel file\n\nCode\nimport os\nsheetname = \"Sheet1\"\nqmdfile = os.getenv(\"QUARTO_DOCUMENT_FILE\")\nfilename = \"img_output/\"+qmdfile[:-4]+\".xlsx\"\nwith pd.ExcelWriter(filename) as writer:\n    next_row = 0\n    for k, v in excel_output.items():\n        pd.DataFrame([k]).to_excel(writer, sheet_name=sheetname, header=False, index=False, startrow=next_row)\n        next_row += 1\n        v.to_excel(writer, sheet_name=sheetname, startrow=next_row, float_format=\"%.1f\")\n        next_row += (\n            (1 if not isinstance(v.columns, pd.MultiIndex) else 1 + len(v.columns.levels))\n            + len(v) + 1)\nprint(f\"[Excel file](./{filename})\")\n\nExcel file"
  },
  {
    "objectID": "4.6_moves_between_services.html",
    "href": "4.6_moves_between_services.html",
    "title": "4.6 Results - Moves between services",
    "section": "",
    "text": "Code\n# Setup code\nimport pandas as pd\nfrom python_scripts import setup\nfrom python_scripts import services\nfrom python_scripts import helper\ndf, dffp = setup.setup(verbose=False)\n\nfrom python_scripts import distinct_pathways\ndpw_pls = distinct_pathways.get_distinct_pathways_routes(dffp)\nqrows = dpw_pls[\"rt_end_cat\"] == \"[Not ended or invalid end reason]\"\ndpw_pls.loc[qrows, \"rt_end_cat\"] = dpw_pls.loc[qrows, \"pl_end_dt\"].isna().map({True: \"[Not ended]\", False: \"Missing data/error\"})\ndpw_pls[\"rt_end_cat\"] = dpw_pls[\"rt_end_cat\"].str.replace(\"To care/hosp.\", \"To care/hospital\")\ndpw_rt_starts = dpw_pls.groupby(\"route_id\").head(1)\ndpw_rt_ends = dpw_pls.groupby(\"route_id\").tail(1)\ndpw_clis = dpw_pls.groupby([\"o_cli_id\"]).head(1)  # 1 duplicate client but first entry has more detailed answers\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nmatplotlib.rcParams.update({\n    'figure.figsize': (6.2, 4.1),\n    'font.size': 12,\n    'figure.constrained_layout.use': True\n})\n\nexcel_output = {}"
  },
  {
    "objectID": "4.6_moves_between_services.html#moves-between-services-rq6",
    "href": "4.6_moves_between_services.html#moves-between-services-rq6",
    "title": "4.6 Results - Moves between services",
    "section": "Moves between services (RQ6)",
    "text": "Moves between services (RQ6)\n\n\nCode\n# Set up networks\nfrom IPython.display import Image, display\nfrom python_scripts.graphics import showImg\nfrom python_scripts import networks\nfrom python_scripts import network_graphs\n\nextant = dpw_pls.groupby(\"o_cli_id\").head(1)[\n    lambda x: x.pl_start_dt &lt; distinct_pathways.dpw_start_dt\n]\nnetwork_definitions = [\n    {\"title\": \"all\", \"df\": dpw_pls},\n]\nDGs = []\nmin_n = 3\nnt = \"svc_typelvl\"\nfor i in network_definitions:\n    title_i, df_i = (i.get(key) for key in [\"title\", \"df\"])\n    sorted_end_cats = distinct_pathways.get_sorted_end_cats(df_i)\n    adj_list_i, edge_list_i = networks.mkAdjEdgeLists(dffp, df_i, [nt])\n    DG = network_graphs.mkDgraph(edge_list_i[nt], title=title_i, threshold=0.07,\n                                 min_n=min_n, sorted_end_cats=sorted_end_cats, capacities=distinct_pathways.capacities,\n                                 individuals=df_i.o_cli_id.nunique())\n    DGs.append(DG)\n    DG = network_graphs.mkDgraph(adj_list_i[nt], title=title_i, threshold=(0.020 * adj_list_i[nt].weight.max()),\n                                 min_n=min_n, sorted_end_cats=sorted_end_cats, capacities=distinct_pathways.capacities,\n                                 individuals=df_i.o_cli_id.nunique())\n    DGs.append(DG)\n\nfig_4_11_svg = \"img_output/Figure_4.11.svg\"\nfig_4_11_png = \"img_output/Figure_4.11.png\"\nDGs[0].draw(format=\"png\", prog=\"neato\", path=fig_4_11_png)\nDGs[0].draw(format=\"svg\", prog=\"neato\", path=fig_4_11_svg)\nfig_4_12_svg = \"img_output/Figure_4.12.svg\"\nfig_4_12_png = \"img_output/Figure_4.12.png\"\nDGs[1].draw(format=\"png\", prog=\"neato\", path=fig_4_12_png)\nDGs[1].draw(format=\"svg\", prog=\"neato\", path=fig_4_12_svg)\n\n\n\nFigure 4.11: Network diagram: proportions of moves out of each node for all BAHSA placements\n\nPNG file\n\n\n\nSVG file\n\nNotes: Oval nodes are levels of services in BAHSA with sizes proportionate to the number of allocated placements on night 1 of the studied period. Rounded rectangles are descriptions of starting points or outcomes. Arrows are moves, with line thickness proportionate to the count/proportion of moves represented. Pathways: F=Female-only, M/F=Mixed, SU=Substance Use, M=Male-only. Levels: L1 (except for SU) is 24-hour hostels, L2 (L1 in SU) is semi-independent supported housing, L3 and L4 (L2 in SU) is mostly accommodation with floating/visiting support.\n\n\n\nFigure 4.12: Network diagram: counts of moves for all BAHSA placements\n\nPNG file\n\n\n\nSVG file\n\nNotes: Oval nodes are levels of services in BAHSA with sizes proportionate to the number of allocated placements on night 1 of the studied period. Rounded rectangles are descriptions of starting points or outcomes. Arrows are moves, with line thickness proportionate to the count/proportion of moves represented. Pathways: F=Female-only, M/F=Mixed, SU=Substance Use, M=Male-only. Levels: L1 (except for SU) is 24-hour hostels, L2 (L1 in SU) is semi-independent supported housing, L3 and L4 (L2 in SU) is mostly accommodation with floating/visiting support."
  }
]