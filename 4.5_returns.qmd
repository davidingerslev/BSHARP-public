---
title: "4.5 Results - Returns"
date: 2026-02-10
warning: false
---

```{python}
# Setup code
import pandas as pd
from python_scripts import setup
from python_scripts import services
from python_scripts import helper
df, dffp = setup.setup(verbose=False)

from python_scripts import distinct_pathways
dpw_pls = distinct_pathways.get_distinct_pathways_routes(dffp)
qrows = dpw_pls["rt_end_cat"] == "[Not ended or invalid end reason]"
dpw_pls.loc[qrows, "rt_end_cat"] = dpw_pls.loc[qrows, "pl_end_dt"].isna().map({True: "[Not ended]", False: "Missing data/error"})
dpw_pls["rt_end_cat"] = dpw_pls["rt_end_cat"].str.replace("To care/hosp.", "To care/hospital")
dpw_rt_starts = dpw_pls.groupby("route_id").head(1)
dpw_rt_ends = dpw_pls.groupby("route_id").tail(1)
dpw_clis = dpw_pls.groupby(["o_cli_id"]).head(1)  # 1 duplicate client but first entry has more detailed answers

import matplotlib
import matplotlib.pyplot as plt
matplotlib.rcParams.update({
    'figure.figsize': (6.2, 4.1),
    'font.size': 12,
    'figure.constrained_layout.use': True
})

excel_output = {}
```

## Returns (RQ5)

### Table 4.3: Returns at periods of time after routes ended (per route)
```{python}
stable_periods = {x: f"after_rt_ret_within_{x}" for x in distinct_pathways.stable_offsets.keys()}
stable_period_max_end_dts = {x: distinct_pathways.dpw_end_dt - distinct_pathways.stable_offsets[x]
                             for x in distinct_pathways.stable_offsets.keys()}
route_end_grp = (dpw_rt_ends[dpw_rt_ends["pl_end_dt"].notnull() & (dpw_rt_ends["rt_end_cat"] != "Died")]
                 .assign(All="All").groupby("All"))
route_outcomes = route_end_grp.size().sort_values(ascending=False).rename(("outcomes", "n")).to_frame()
route_outcomes[("outcomes", "%")] = (100*route_outcomes[("outcomes", "n")]
                                     / route_outcomes[("outcomes", "n")].sum())
for k, v in stable_periods.items():
    route_outcomes[k, f"<t"] = (route_end_grp["pl_end_dt"]
                                .apply(lambda x: (x >= stable_period_max_end_dts[k]).sum()).astype("Int64"))
    route_outcomes[k, f">=t"] = (route_end_grp["pl_end_dt"]
                                 .apply(lambda x: (x < stable_period_max_end_dts[k]).sum()).astype("Int64"))
    route_outcomes[k, f"<t ret"] = (route_end_grp
                                    .apply(lambda x: ((x["pl_end_dt"] >= stable_period_max_end_dts[k])
                                                      & (x[v] == "Yes")).sum()).astype("Int64"))
    # route_outcomes[k, f"<t"] = route_end_grp[v].apply(lambda x: (x == "Not yet...").sum()).astype("Int64")
    for outcome in ["Yes", "No"]:
        route_outcomes[k, outcome] = (route_end_grp
                                      .apply(lambda x: ((x["pl_end_dt"] < stable_period_max_end_dts[k])
                                                        & (x[v] == outcome)).sum()).astype("Int64"))
    route_outcomes[k, "Y+N"] = (route_outcomes[k, "Yes"]
                                + route_outcomes[k, "No"])
    route_outcomes[k, "% Y/(Y+N)"] = (route_outcomes[k, "Yes"]
                                      .mul(100).div(route_outcomes[k, "Yes"]
                                                    + route_outcomes[k, "No"]))
    route_outcomes[k, "% No/sum(n)"] = (route_outcomes[k, "No"]
                                        .mul(100).div(route_outcomes[("outcomes", "n")].sum()))
tbl_periods = route_outcomes.astype("object").iloc[:, 2:].stack()
t4_3 = route_outcomes.astype("object").iloc[:, 2:].stack().loc["All"].loc[[">=t", "Yes", "% Y/(Y+N)"]]
t4_3.loc["% N/(Y+N)"] = 100 - t4_3.loc["% Y/(Y+N)"]
t4_3 = t4_3.rename(index={">=t": "Eligible routes",
                          "Yes": "Subsequent returns",
                          "% Y/(Y+N)": "% returned",
                          "% N/(Y+N)": "% not returned"})
with pd.option_context("display.float_format", "{:,.1f}".format):
    display(t4_3)
excel_output["Table 4.3: Returns at periods of time after routes ended (per route)"] = t4_3
```
<sup>Notes: 1. Return = new route that started before 30/04/2025.</sup>

### Table 4.4: Returns at periods of time after peopleâ€™s first routes ended (per person)

```{python}
stable_periods = {x: f"after_rt_ret_within_{x}" for x in distinct_pathways.stable_offsets.keys()}
stable_period_max_end_dts = {x: distinct_pathways.dpw_end_dt - distinct_pathways.stable_offsets[x]
                             for x in distinct_pathways.stable_offsets.keys()}
pl_before_dpw_start = dffp.loc[(dffp["pl_start_dt"] < distinct_pathways.dpw_start_dt), "o_cli_id"].unique()
dpw_clis_before_start = dpw_clis.loc[dpw_clis["o_cli_id"].isin(pl_before_dpw_start), "o_cli_id"]
first_dpw_routes = dpw_pls.groupby("o_cli_id").head(1)["route_id"]
first_route_end_pls = (dpw_pls[dpw_pls["route_id"].isin(first_dpw_routes)]
                       .groupby("route_id").tail(1)[lambda x: x["pl_end_dt"].notnull() & (x["rt_end_cat"] != "Died")]
                       .assign(Group=lambda x: x["o_cli_id"].isin(dpw_clis_before_start).map({True: "Prev", False: "New"})))
first_route_end_grp = pd.concat([first_route_end_pls, first_route_end_pls.assign(Group="All")]).groupby("Group")
first_route_outcomes = first_route_end_grp.size().sort_values(ascending=False).rename(("outcomes", "n")).to_frame()
first_route_outcomes[("outcomes", "%")] = (100*first_route_outcomes[("outcomes", "n")]
                                           / first_route_outcomes.loc["All", ("outcomes", "n")])
for k, v in stable_periods.items():
    first_route_outcomes[k, f"<t"] = (first_route_end_grp["pl_end_dt"]
                                      .apply(lambda x: (x >= stable_period_max_end_dts[k]).sum()).astype("Int64"))
    first_route_outcomes[k, f">=t"] = (first_route_end_grp["pl_end_dt"]
                                       .apply(lambda x: (x < stable_period_max_end_dts[k]).sum()).astype("Int64"))
    first_route_outcomes[k, f"<t ret"] = (first_route_end_grp
                                          .apply(lambda x: ((x["pl_end_dt"] >= stable_period_max_end_dts[k])
                                                            & (x[v] == "Yes")).sum()).astype("Int64"))
    # first_route_outcomes[k, f"<t"] = first_route_end_grp[v].apply(lambda x: (x == "Not yet...").sum()).astype("Int64")
    for outcome in ["Yes", "No"]:
        first_route_outcomes[k, outcome] = (first_route_end_grp
                                            .apply(lambda x: ((x["pl_end_dt"] < stable_period_max_end_dts[k])
                                                              & (x[v] == outcome)).sum()).astype("Int64"))
    first_route_outcomes[k, "Y+N"] = (first_route_outcomes[k, "Yes"]
                                      + first_route_outcomes[k, "No"])
    first_route_outcomes[k, "% Y/(Y+N)"] = (first_route_outcomes[k, "Yes"]
                                            .mul(100).div(first_route_outcomes[k, "Yes"]
                                                          + first_route_outcomes[k, "No"]))
    first_route_outcomes[k, "% No/sum(n)"] = (first_route_outcomes[k, "No"]
                                              .mul(100).div(first_route_outcomes[("outcomes", "n")].sum()))


tbl_n = first_route_outcomes.iloc[:, :2].sort_index(ascending=False)
tbl_periods = first_route_outcomes.astype("object").iloc[:, 2:].stack().sort_index(level=0, ascending=False, sort_remaining=False)
t4_4 = tbl_periods.loc["All"].loc[[">=t", "Yes", "% Y/(Y+N)"]]
t4_4.loc["% N/(Y+N)"] = 100 - t4_4.loc["% Y/(Y+N)"]
t4_4 = t4_4.rename(index={">=t": "Eligible first routes",
                          "Yes": "Subsequent returns",
                          "% Y/(Y+N)": "% returned",
                          "% N/(Y+N)": "% not returned"})
with pd.option_context("display.float_format", "{:,.1f}".format):
    display(t4_4)
```

### Figure 4.9: Returns at periods of time after exits

```{python}
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn.objects as so
periodMult = {"d": 1, "m": 365.25/12, "y": 365.25}
periodYears = {x: int(x[:-1]) * periodMult[x[-1]] / periodMult["y"] for x in distinct_pathways.stable_offsets.keys()}
plotdata = (
    pd.concat([
        t4_3.loc["% returned"].to_frame()
        .assign(years=lambda x: x.index.map(periodYears), grp="Per route (all exits)")
        .reset_index(),
        t4_4.loc["% returned"].to_frame()
        .assign(years=lambda x: x.index.map(periodYears), grp="Per person (first exits)")
        .reset_index()
    ])
)
grps = plotdata["grp"].unique()
plotdata = (
    pd.concat([pd.DataFrame({"index": "", "% returned": 0, "years": 0, "grp": grps}, index=[""]*len(grps)), plotdata])
    .reset_index(drop=True))
p = (
    so.Plot(data=plotdata, y="% returned", x="years", text="index")
    .facet(col="grp")
    .label(x="years since exit")
    .add(so.Dot(), data=plotdata[plotdata["index"] != ""])
    .add(so.Line())
    .add(so.Area(edgewidth=0))
    .add(so.Text(halign="left", valign="top"))
    .limit(x=(0, 5.5), y=(0, 40))
    .scale(x=so.Continuous().tick(minor=1))
    .theme({"axes.grid.which": "both"})
    .layout(size=(6.2, 3.6), engine="constrained")
)
fig_4_9 = "img_output/Figure_4.9.svg"
p.save(fig_4_9)
pass
```

![](`{python} fig_4_9`)

<sup>Note: Data tables are Table 4.3 and Table 4.4.</sup>

### Table A.8: Returns at periods of time after exit by end reason

```{python}
# Generate table
stable_periods = {x: f"after_rt_ret_within_{x}" for x in distinct_pathways.stable_offsets.keys()}
stable_period_max_end_dts = {x: distinct_pathways.dpw_end_dt - distinct_pathways.stable_offsets[x]
                             for x in distinct_pathways.stable_offsets.keys()}
route_end_grp = (dpw_rt_ends[dpw_rt_ends["pl_end_dt"].notnull() & (dpw_rt_ends["rt_end_cat"] != "Died")]
                 .assign(All="All").groupby("rt_end_cat"))
route_outcomes = route_end_grp.size().sort_values(ascending=False).rename(("outcomes", "n")).to_frame()
route_outcomes[("outcomes", "%")] = (100*route_outcomes[("outcomes", "n")]
                                     / route_outcomes[("outcomes", "n")].sum())
for k, v in stable_periods.items():
    route_outcomes[k, f"Eligible (n)"] = (route_end_grp["pl_end_dt"]
                                 .apply(lambda x: (x < stable_period_max_end_dts[k]).sum()).astype("Int64"))
    for outcome in ["Yes", "No"]:
        route_outcomes[k, outcome] = (route_end_grp
                                      .apply(lambda x: ((x["pl_end_dt"] < stable_period_max_end_dts[k])
                                                        & (x[v] == outcome)).sum()).astype("Int64"))
    route_outcomes[k, "% returned"] = (route_outcomes[k, "Yes"]
                                       .mul(100).div(route_outcomes[k, "Yes"]
                                                     + route_outcomes[k, "No"]))
    route_outcomes = route_outcomes.drop(columns=(k, "No"))
    route_outcomes = route_outcomes.rename(columns={"Yes": "Returned (n)"}, level=1)
na_cols = ["[Not ended]", "Died"]
route_outcomes = route_outcomes.sort_values(("outcomes", "%"), ascending=False)
ta8_n = route_outcomes.iloc[:, :2]
route_outcomes = route_outcomes.sort_values(("2y", "% returned"), ascending=True)
ta8_periods = (route_outcomes.astype("object")
               .loc[[x for x in route_outcomes.index.to_list() if x not in na_cols]]
               .iloc[:, 2:].stack(sort=False))
ta8 = ta8_periods
ta8.index = ta8.index.set_names(("End reason", "Statistic"))
with pd.option_context("display.float_format", "{:,.1f}".format):
    display(ta8)

excel_output["Table A.8: Returns at periods of time after exit by end reason"] = ta8
```

### Figure 4.10: Return proportions at periods of time after eligible exits by end reason
```{python}
# Plot chart
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn.objects as so
periodMult = {"d": 1, "m": 365.25/12, "y": 365.25}
periodYears = {x: int(x[:-1]) * periodMult[x[-1]] / periodMult["y"] for x in distinct_pathways.stable_offsets.keys()}
plotdata = (
    ta8.unstack(0).loc["% returned"].reset_index(1)
    .assign(years=lambda x: x.index.map(periodYears))
    .reset_index()
)
zeroes = pd.DataFrame({"index": "", "End reason": plotdata["End reason"].unique(), "% returned": 0, "years": 0},
                      index=range(len(plotdata), len(plotdata) + plotdata["End reason"].nunique()))
plotdata = pd.concat([zeroes, plotdata])
facet_order = ta8_n.index.to_list()
p = (
    so.Plot(data=plotdata, y="% returned", x="years", text="index")
    .facet("End reason", wrap=4, order=facet_order)
    .label(x="", y="")
    .add(so.Dot(), data=plotdata[plotdata["index"] != ""])
    .add(so.Line())
    .add(so.Area(edgewidth=0))
    .limit(x=(0, 5), y=(0, None))
    .scale(x=(so.Continuous()
              .tick(every=1, minor=0)
              .label(like=lambda x, pos: f"{x:.0f}" if x != 5 else "5y")),
           y=so.Continuous().tick(minor=1).label(unit=("", "%")))
    .theme({"axes.grid.which": "both"})
    .layout(size=(7.2, 4.1), engine="constrained")
)
fig_4_10 = "img_output/Figure_4.10.svg"
p.save(fig_4_10)
pass
```

![](`{python} fig_4_10`)

<sup>Note: Data table is Table A.8. Figure B.1 shows return and eligible exit counts per end reason.</sup>

### Figure B.1: Number of returns at periods of time after eligible exits by end reason

```{python}
#| output: false
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn.objects as so
sns.set_theme()
periodMult = {"d": 1, "m": 365.25/12, "y": 365.25}
periodYears = {x: int(x[:-1]) * periodMult[x[-1]] / periodMult["y"] for x in distinct_pathways.stable_offsets.keys()}
plotdata = (
    ta8_periods.unstack(0).loc[["Eligible (n)", "Returned (n)"]].T.reset_index(1)
    .assign(Yes=lambda x: x["Returned (n)"], No=lambda x: x["Eligible (n)"])[["End reason", "Yes", "No"]]
    .assign(years=lambda x: x.index.map(periodYears))
)
zeroes = pd.DataFrame({"End reason": ta8_n.index, "Yes": 0, "No": ta8_n[("outcomes", "n")].values, "years": 0},
                      index=[""] * len(ta8_n))
plotdata = pd.concat([zeroes, plotdata])
facet_order = ta8_n.index.to_list()
plotdata = (plotdata.reset_index().set_index(["index", "years", "End reason"]).stack().reset_index()
            .rename(columns={"level_3": "Returned", 0: "n"}))
fig = plt.figure(figsize=[7.2, 4.1])
p = (
    so.Plot(data=plotdata, y="n", x="years", color="Returned", text="index")
    .facet("End reason", wrap=4, order=facet_order)
    .label(x="", y="")
    .add(so.Dot(), so.Stack(), legend=False)
    .add(so.Line(), so.Stack(), legend=False)
    .add(so.Area(edgewidth=0), so.Stack(), legend=False)
    .limit(x=(0, 5), y=(0, None))
    .scale(x=(so.Continuous()
              .tick(every=1, minor=0)
              .label(like=lambda x, pos: f"{x:.0f}" if x != 5 else "5y")),
           y=so.Continuous().tick(minor=3))
    # .scale(x=so.Continuous().tick(every=5, minor=4).label(unit=("", "y")), y=so.Continuous().tick(minor=3))
    .theme({"axes.grid.which": "both"})
    .layout(size=(7.2, 4.1), engine="constrained")
    .on(fig)
)
colours = sns.color_palette(as_cmap=False)
Y = matplotlib.patches.Patch(facecolor=colours[0], edgecolor="white", alpha=0.8, label="$\mathregular{n_{returned}}$")
N = matplotlib.patches.Patch(facecolor=colours[1], edgecolor="white", alpha=0.8, label="$\mathregular{n_{eligible}}$")
fig.legend(loc="lower right", handles=[N, Y])
fig_b_1 = "img_output/Figure_B.1.svg"
p.save(fig_b_1)
pass
```

![](`{python} fig_b_1`)

Figure B.1 shows eligible exits and returns, highlighting the effect of lower numbers of
eligible exits over longer time periods. Figure 4.9 is derived from this set of charts by
dividing the number of returns by the number of eligible exits, i.e. normalising by *n*<sub>eligible</sub>,
to show the proportions of returns at different times after exits for different end reasons.

### Figure B.2: Number of returns (cumulative) by time since exits for preceding end reasons

```{python}
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import seaborn.objects as so
from python_scripts import routes
hist_data = ((dpw_rt_starts.loc[dpw_rt_starts["gap"].notna(), "gap"].dt.days.astype("float64")).rename("Days").to_frame()
             .assign(Previous_End_Reason=dpw_rt_starts["prev_pl_end_reason"].map(routes.get_end_cats_map())))
plotdata = hist_data.groupby(["Previous_End_Reason", "Days"]).size().rename("Count").groupby("Previous_End_Reason").cumsum().to_frame()
max_counts = (plotdata.reset_index().groupby("Previous_End_Reason")["Count"].max()
              .to_frame().assign(Days=plotdata.reset_index()["Days"].max())
              .set_index("Days", append=True))
plotdata = pd.concat([plotdata, max_counts]).reset_index().drop_duplicates().set_index(["Previous_End_Reason", "Days"])
markers = []
for x_val in [x * 365.25 for x in [0.5, 1, 2, 3, 4]]:
    markers = markers + [(hist_data.groupby("Previous_End_Reason")["Days"].agg(lambda x: (x <= x_val).sum())
                         .rename("Count").to_frame().assign(Days=x_val).set_index("Days", append=True))]
markers = pd.concat(markers)
markers = markers.assign(Pct=(100 * markers / max_counts.droplevel("Days")).map(lambda x: f"{x:.0f}%"))
zeroes = pd.DataFrame(plotdata.index.levels[0]).assign(Days=0, Count=0, Marker=False).set_index(["Previous_End_Reason", "Days"])
plotdata = pd.concat([zeroes, plotdata.assign(Pct="", Marker=False), markers.assign(Marker=True)])
facet_order=hist_data["Previous_End_Reason"].value_counts().index.to_list()
figs = []
for y_max, y_tick, suffix, fig in [(None, 150, "", "Figure_B.2_a"), (100, 25, " (zoomed)", "Figure_B.2_b")]:
    limits = {"x": (0, hist_data["Days"].max()), "y": (None, y_max)}
    markers_max = y_max if y_max is not None else markers["Count"].max()
    markers_data = plotdata[plotdata["Marker"] & (plotdata["Count"] < markers_max)]
    p = (
        so.Plot(data=plotdata, x="Days", y="Count")
        .label(x="", y="")
        .add(so.Area(edgewidth=0))
        .add(so.Line())
        .scale(x=so.Continuous().tick(every=365.25).label(like=lambda x, y: f"{x/365.25:.0f}"),
            y=so.Continuous().tick(every=y_tick))
        .limit(x=limits["x"], y=limits["y"])
        .layout(size=(7.2, 4.1), engine="constrained")
        .facet(col="Previous_End_Reason", wrap=4, order=facet_order)
    )
    p.save(f"img_output/{fig}.svg")
    figs.append(f"img_output/{fig}.svg")
extrafigs = []
for y_max, y_tick, suffix, plotdata, markers in [(None,
                                                  5,
                                                  " (social or private)",
                                                  plotdata.loc[["To private rented", "To social housing"]].reset_index().set_index(["Previous_End_Reason", "Days"]),
                                                  markers.loc[["To private rented", "To social housing"]].reset_index().set_index(["Previous_End_Reason", "Days"]))]:
    limits = {"x": (0, hist_data["Days"].max()), "y": (None, y_max)}
    markers_max = y_max if y_max is not None else markers["Count"].max()
    markers_data = plotdata[plotdata["Marker"] & (plotdata["Count"] < markers_max)]
    p = (
        so.Plot(data=plotdata, x="Days", y="Count")
        .label(x="Preceding gap in years", y="Returns (cumulative count)")
        .add(so.Area(edgewidth=0))
        .add(so.Line())
        # .add(so.Dot(pointsize=4.5), data=markers_data)
        # .add(so.Text({"clip_on": False}, fontsize=7, halign="left", valign="top", offset=2), data=markers_data, text="Pct")
        .scale(x=so.Continuous().tick(every=365.25).label(like=lambda x, y: f"{x/365.25:.0f}"),
            y=so.Continuous().tick(every=y_tick))
        .limit(x=limits["x"], y=limits["y"])
        .layout(size=(7.2, 4.1), engine="constrained")
        .facet(col="Previous_End_Reason")
    )
    p.save("img_output/Figure_B.3.svg")
    extrafigs.append("img_output/Figure_B.3.svg")
```

![](`{python} figs[0]`)

Increased y-scale (zoomed-in)

![](`{python} figs[1]`)

### Extra figure: Number of returns (cumulative) by time since exits for social and private rented housing outcomes

Further increased y-scale (zoomed-in to maximum)

![](`{python} extrafigs[0]`)

## Tables in an Excel file

```{python}
#| output: asis
import os
sheetname = "Sheet1"
qmdfile = os.getenv("QUARTO_DOCUMENT_FILE")
filename = "img_output/"+qmdfile[:-4]+".xlsx"
with pd.ExcelWriter(filename) as writer:
    next_row = 0
    for k, v in excel_output.items():
        pd.DataFrame([k]).to_excel(writer, sheet_name=sheetname, header=False, index=False, startrow=next_row)
        next_row += 1
        v.to_excel(writer, sheet_name=sheetname, startrow=next_row, float_format="%.1f")
        next_row += (
            (1 if not isinstance(v.columns, pd.MultiIndex) else 1 + len(v.columns.levels))
            + len(v) + 1)
print(f"[Excel file](./{filename})")
```
